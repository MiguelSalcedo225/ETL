{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6af647b",
   "metadata": {},
   "source": [
    "## 1. Importar librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "b3259e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "from sqlalchemy import create_engine, text, inspect\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44cf277",
   "metadata": {},
   "source": [
    "## 2. Cargar configuración desde config.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "90b367f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuración PostgreSQL: {'drivername': 'postgresql', 'dbname': 'prueba', 'user': 'postgres', 'password': 'postgres', 'host': 'localhost', 'port': 5432}\n",
      "\n",
      "Configuración SQL Server: {'drivername': 'mssql+pyodbc', 'dbname': 'AdventureWorksDW2022', 'user': 'sa', 'password': 'r00t.R00T', 'host': 'localhost', 'port': 1433, 'driver': 'FreeTDS'}\n"
     ]
    }
   ],
   "source": [
    "# Cargar configuración\n",
    "with open('../config.yml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Obtener configuraciones específicas\n",
    "config_postgres = config['ETL_PRO']\n",
    "config_sqlserver = config['SQL_SERVER_DW']\n",
    "\n",
    "print(\"Configuración PostgreSQL:\", config_postgres)\n",
    "print(\"\\nConfiguración SQL Server:\", config_sqlserver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245e89c9",
   "metadata": {},
   "source": [
    "## 3. Conexión a PostgreSQL (ETL_PRO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "35715129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectado exitosamente a PostgreSQL\n",
      "Versión: PostgreSQL 17.6 (Debian 17.6-2.pgdg13+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 14.2.0-19) 14.2.0, 64-bit\n"
     ]
    }
   ],
   "source": [
    "# Construir URL de conexión para PostgreSQL\n",
    "url_postgres = (\n",
    "    f\"{config_postgres['drivername']}://\"\n",
    "    f\"{config_postgres['user']}:{config_postgres['password']}@\"\n",
    "    f\"{config_postgres['host']}:{config_postgres['port']}/\"\n",
    "    f\"{config_postgres['dbname']}\"\n",
    ")\n",
    "\n",
    "# Crear engine de SQLAlchemy para PostgreSQL\n",
    "engine_postgres = create_engine(url_postgres)\n",
    "\n",
    "# Verificar conexión\n",
    "try:\n",
    "    with engine_postgres.connect() as conn:\n",
    "        result = conn.execute(text(\"SELECT version();\"))\n",
    "        version = result.fetchone()\n",
    "        print(\"Conectado exitosamente a PostgreSQL\")\n",
    "        print(f\"Versión: {version[0]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al conectar a PostgreSQL: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90e3c4d",
   "metadata": {},
   "source": [
    "## 4. Conexión a SQL Server (AdventureWorksDW2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "9133f82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectado exitosamente a SQL Server\n",
      "Versión: Microsoft SQL Server 2022 (RTM-CU21) (KB5065865) - 16.0.4215.2 (X64) \n",
      "\tAug 11 2025 13:24:21 \n",
      "\tCopyri...\n"
     ]
    }
   ],
   "source": [
    "# Construir URL de conexión para SQL Server\n",
    "# Nota: Asegúrate de tener instalado pyodbc y el driver ODBC para SQL Server\n",
    "url_sqlserver = (\n",
    "    f\"{config_sqlserver['drivername']}://\"\n",
    "    f\"{config_sqlserver['user']}:{config_sqlserver['password']}@\"\n",
    "    f\"{config_sqlserver['host']}:{config_sqlserver['port']}/\"\n",
    "    f\"{config_sqlserver['dbname']}\"\n",
    "    f\"?driver={config_sqlserver['driver'].replace(' ', '+')}\"\n",
    ")\n",
    "\n",
    "# Crear engine de SQLAlchemy para SQL Server\n",
    "engine_sqlserver = create_engine(url_sqlserver)\n",
    "\n",
    "# Verificar conexión\n",
    "try:\n",
    "    with engine_sqlserver.connect() as conn:\n",
    "        result = conn.execute(text(\"SELECT @@VERSION;\"))\n",
    "        version = result.fetchone()\n",
    "        print(\"Conectado exitosamente a SQL Server\")\n",
    "        print(f\"Versión: {version[0][:100]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al conectar a SQL Server: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6c2689",
   "metadata": {},
   "source": [
    "## 5. Ejemplo: Listar tablas en ambas bases de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "f21045c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "TABLAS EN POSTGRESQL (ETL_PRO)\n",
      "==================================================\n",
      "1. dim_product\n",
      "2. dim_date\n",
      "3. dim_salesterritory\n",
      "4. dim_salesreason\n",
      "5. dim_currency\n",
      "6. dim_promotion\n",
      "7. dim_customer\n",
      "8. dim_employee\n",
      "9. dim_geography\n",
      "10. dim_reseller\n",
      "11. fact_internet_sales\n",
      "12. fact_internet_sales_reason\n",
      "\n",
      "Total: 12 tablas\n",
      "\n",
      "==================================================\n",
      "TABLAS EN SQL SERVER (AdventureWorksDW2022)\n",
      "==================================================\n",
      "1. AdventureWorksDWBuildVersion\n",
      "2. DatabaseLog\n",
      "3. DimAccount\n",
      "4. DimCurrency\n",
      "5. DimCustomer\n",
      "6. DimDate\n",
      "7. DimDepartmentGroup\n",
      "8. DimEmployee\n",
      "9. DimGeography\n",
      "10. DimOrganization\n",
      "11. DimProduct\n",
      "12. DimProductCategory\n",
      "13. DimProductSubcategory\n",
      "14. DimPromotion\n",
      "15. DimReseller\n",
      "16. DimSalesReason\n",
      "17. DimSalesTerritory\n",
      "18. DimScenario\n",
      "19. FactAdditionalInternationalProductDescription\n",
      "20. FactCallCenter\n",
      "21. FactCurrencyRate\n",
      "22. FactFinance\n",
      "23. FactInternetSales\n",
      "24. FactInternetSalesReason\n",
      "25. FactProductInventory\n",
      "26. FactResellerSales\n",
      "27. FactSalesQuota\n",
      "28. FactSurveyResponse\n",
      "29. NewFactCurrencyRate\n",
      "30. ProspectiveBuyer\n",
      "31. sysdiagrams\n",
      "\n",
      "Total: 31 tablas\n"
     ]
    }
   ],
   "source": [
    "# Listar tablas en PostgreSQL\n",
    "print(\"=\" * 50)\n",
    "print(\"TABLAS EN POSTGRESQL (ETL_PRO)\")\n",
    "print(\"=\" * 50)\n",
    "inspector_pg = inspect(engine_postgres)\n",
    "tables_pg = inspector_pg.get_table_names()\n",
    "for i, table in enumerate(tables_pg, 1):\n",
    "    print(f\"{i}. {table}\")\n",
    "\n",
    "print(f\"\\nTotal: {len(tables_pg)} tablas\")\n",
    "\n",
    "# Listar tablas en SQL Server\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"TABLAS EN SQL SERVER (AdventureWorksDW2022)\")\n",
    "print(\"=\" * 50)\n",
    "try:\n",
    "    inspector_ss = inspect(engine_sqlserver)\n",
    "    tables_ss = inspector_ss.get_table_names()\n",
    "    for i, table in enumerate(tables_ss, 1):\n",
    "        print(f\"{i}. {table}\")\n",
    "    print(f\"\\nTotal: {len(tables_ss)} tablas\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al listar tablas de SQL Server: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "8787a477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL (dim_product): 606\n",
      "Registros en SQL Server (DimProduct): 606\n",
      "\n",
      "================================================================================\n",
      "Mismo numero de registros: 606\n",
      "\n",
      "================================================================================\n",
      "COLUMNAS:\n",
      "\n",
      "PostgreSQL: ['productkey', 'productalternatekey', 'productsubcategorykey', 'weightunitmeasurecode', 'sizeunitmeasurecode', 'englishproductname', 'standardcost', 'finishedgoodsflag', 'color', 'safetystocklevel', 'reorderpoint', 'listprice', 'size', 'sizerange', 'weight', 'daystomanufacture', 'productline', 'dealerprice', 'class', 'style', 'modelname', 'largephoto', 'englishdescription', 'startdate', 'enddate', 'status', 'saved']\n",
      "\n",
      "SQL Server: ['ProductKey', 'ProductAlternateKey', 'ProductSubcategoryKey', 'WeightUnitMeasureCode', 'SizeUnitMeasureCode', 'EnglishProductName', 'SpanishProductName', 'FrenchProductName', 'StandardCost', 'FinishedGoodsFlag', 'Color', 'SafetyStockLevel', 'ReorderPoint', 'ListPrice', 'Size', 'SizeRange', 'Weight', 'DaysToManufacture', 'ProductLine', 'DealerPrice', 'Class', 'Style', 'ModelName', 'LargePhoto', 'EnglishDescription', 'FrenchDescription', 'ChineseDescription', 'ArabicDescription', 'HebrewDescription', 'ThaiDescription', 'GermanDescription', 'JapaneseDescription', 'TurkishDescription', 'StartDate', 'EndDate', 'Status']\n",
      "\n",
      "================================================================================\n",
      "Columnas comunes para comparar: 26\n",
      "['class', 'color', 'daystomanufacture', 'dealerprice', 'enddate', 'englishdescription', 'englishproductname', 'finishedgoodsflag', 'largephoto', 'listprice', 'modelname', 'productalternatekey', 'productkey', 'productline', 'productsubcategorykey', 'reorderpoint', 'safetystocklevel', 'size', 'sizerange', 'sizeunitmeasurecode', 'standardcost', 'startdate', 'status', 'style', 'weight', 'weightunitmeasurecode']\n",
      "\n",
      "================================================================================\n",
      "COMPARACION DE DATOS:\n",
      "\n",
      "Diferencias en columna 'color': 254 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 0: PG='None' vs SS='NA'\n",
      "   - Fila 1: PG='None' vs SS='NA'\n",
      "   - Fila 2: PG='None' vs SS='NA'\n",
      "   - Fila 3: PG='None' vs SS='NA'\n",
      "   - Fila 4: PG='None' vs SS='NA'\n",
      "\n",
      "Diferencias en columna 'dealerprice': 329 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 211: PG='30.8402' vs SS='20.1865'\n",
      "   - Fila 212: PG='30.8402' vs SS='20.1865'\n",
      "   - Fila 213: PG='30.8402' vs SS='20.994'\n",
      "   - Fila 214: PG='30.399' vs SS='20.1865'\n",
      "   - Fila 215: PG='30.399' vs SS='20.1865'\n",
      "\n",
      "Diferencias en columna 'enddate': 200 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 211: PG='2012-05-29 00:00:00+00:00' vs SS='2007-12-28 00:00:00'\n",
      "   - Fila 212: PG='2013-05-29 00:00:00+00:00' vs SS='2008-12-27 00:00:00'\n",
      "   - Fila 214: PG='2012-05-29 00:00:00+00:00' vs SS='2007-12-28 00:00:00'\n",
      "   - Fila 215: PG='2013-05-29 00:00:00+00:00' vs SS='2008-12-27 00:00:00'\n",
      "   - Fila 217: PG='2012-05-29 00:00:00+00:00' vs SS='2007-12-28 00:00:00'\n",
      "\n",
      "Diferencias en columna 'englishdescription': 210 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 0: PG='' vs SS='None'\n",
      "   - Fila 1: PG='' vs SS='None'\n",
      "   - Fila 2: PG='' vs SS='None'\n",
      "   - Fila 3: PG='' vs SS='None'\n",
      "   - Fila 4: PG='' vs SS='None'\n",
      "\n",
      "Diferencias en columna 'largephoto': 606 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 0: PG='\\x474946383961f0009500f700000000008000000080008080' vs SS='b'GIF89a\\xf0\\x00\\x95\\x00\\xf7\\x00\\x00\\x00\\x00\\x00\\x'\n",
      "   - Fila 1: PG='\\x474946383961f0009500f700000000008000000080008080' vs SS='b'GIF89a\\xf0\\x00\\x95\\x00\\xf7\\x00\\x00\\x00\\x00\\x00\\x'\n",
      "   - Fila 2: PG='\\x474946383961f0009500f700000000008000000080008080' vs SS='b'GIF89a\\xf0\\x00\\x95\\x00\\xf7\\x00\\x00\\x00\\x00\\x00\\x'\n",
      "   - Fila 3: PG='\\x474946383961f0009500f700000000008000000080008080' vs SS='b'GIF89a\\xf0\\x00\\x95\\x00\\xf7\\x00\\x00\\x00\\x00\\x00\\x'\n",
      "   - Fila 4: PG='\\x474946383961f0009500f700000000008000000080008080' vs SS='b'GIF89a\\xf0\\x00\\x95\\x00\\xf7\\x00\\x00\\x00\\x00\\x00\\x'\n",
      "\n",
      "Diferencias en columna 'listprice': 12 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 295: PG='1191.174' vs SS='1191.1739'\n",
      "   - Fila 296: PG='1226.909' vs SS='1226.9091'\n",
      "   - Fila 300: PG='1191.174' vs SS='1191.1739'\n",
      "   - Fila 301: PG='1226.909' vs SS='1226.9091'\n",
      "   - Fila 303: PG='1191.174' vs SS='1191.1739'\n",
      "\n",
      "Diferencias en columna 'sizerange': 218 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 209: PG='58-60 CM' vs SS='54-58 CM'\n",
      "   - Fila 210: PG='58-60 CM' vs SS='54-58 CM'\n",
      "   - Fila 237: PG='62-64 CM' vs SS='60-62 CM'\n",
      "   - Fila 238: PG='62-64 CM' vs SS='60-62 CM'\n",
      "   - Fila 239: PG='62-64 CM' vs SS='60-62 CM'\n",
      "\n",
      "Diferencias en columna 'standardcost': 313 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 0: PG='0.0' vs SS='nan'\n",
      "   - Fila 1: PG='0.0' vs SS='nan'\n",
      "   - Fila 2: PG='0.0' vs SS='nan'\n",
      "   - Fila 3: PG='0.0' vs SS='nan'\n",
      "   - Fila 4: PG='0.0' vs SS='nan'\n",
      "\n",
      "Diferencias en columna 'startdate': 606 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 0: PG='NaT' vs SS='2003-07-01 00:00:00'\n",
      "   - Fila 1: PG='NaT' vs SS='2003-07-01 00:00:00'\n",
      "   - Fila 2: PG='NaT' vs SS='2003-07-01 00:00:00'\n",
      "   - Fila 3: PG='NaT' vs SS='2003-07-01 00:00:00'\n",
      "   - Fila 4: PG='NaT' vs SS='2003-07-01 00:00:00'\n",
      "\n",
      "================================================================================\n",
      "Se encontraron diferencias entre las tablas.\n",
      "\n",
      "Se exportaron 2748 diferencias al archivo: diferencias_dim_product.csv\n",
      "Total de filas unicas con diferencias: 606\n",
      "\n",
      "Columnas con diferencias:\n",
      "columna_diferente\n",
      "largephoto            606\n",
      "startdate             606\n",
      "dealerprice           329\n",
      "standardcost          313\n",
      "color                 254\n",
      "sizerange             218\n",
      "englishdescription    210\n",
      "enddate               200\n",
      "listprice              12\n",
      "Name: count, dtype: int64\n",
      "\n",
      "================================================================================\n",
      "\n",
      "MUESTRA DE DATOS (primeras 3 filas):\n",
      "\n",
      "PostgreSQL (dim_product):\n",
      "   productkey productalternatekey  productsubcategorykey  \\\n",
      "0           1             AR-5381                    NaN   \n",
      "1           2             BA-8327                    NaN   \n",
      "2           3             BE-2349                    NaN   \n",
      "\n",
      "  weightunitmeasurecode sizeunitmeasurecode englishproductname  standardcost  \\\n",
      "0                  None                None    Adjustable Race           0.0   \n",
      "1                  None                None       Bearing Ball           0.0   \n",
      "2                  None                None    BB Ball Bearing           0.0   \n",
      "\n",
      "   finishedgoodsflag color  safetystocklevel  reorderpoint  listprice  size  \\\n",
      "0              False  None              1000           750        NaN  None   \n",
      "1              False  None              1000           750        NaN  None   \n",
      "2              False  None               800           600        NaN  None   \n",
      "\n",
      "  sizerange  weight  daystomanufacture productline  dealerprice class style  \\\n",
      "0        NA     NaN                  0        None          NaN  None  None   \n",
      "1        NA     NaN                  0        None          NaN  None  None   \n",
      "2        NA     NaN                  1        None          NaN  None  None   \n",
      "\n",
      "  modelname                                         largephoto  \\\n",
      "0      None  \\x474946383961f0009500f70000000000800000008000...   \n",
      "1      None  \\x474946383961f0009500f70000000000800000008000...   \n",
      "2      None  \\x474946383961f0009500f70000000000800000008000...   \n",
      "\n",
      "  englishdescription startdate enddate   status                      saved  \n",
      "0                          NaT     NaT  Current 2025-11-16 19:01:18.570381  \n",
      "1                          NaT     NaT  Current 2025-11-16 19:01:18.570381  \n",
      "2                          NaT     NaT  Current 2025-11-16 19:01:18.570381  \n",
      "\n",
      "SQL Server (DimProduct):\n",
      "   ProductKey ProductAlternateKey  ProductSubcategoryKey  \\\n",
      "0           1             AR-5381                    NaN   \n",
      "1           2             BA-8327                    NaN   \n",
      "2           3             BE-2349                    NaN   \n",
      "\n",
      "  WeightUnitMeasureCode SizeUnitMeasureCode EnglishProductName  \\\n",
      "0                  None                None    Adjustable Race   \n",
      "1                  None                None       Bearing Ball   \n",
      "2                  None                None    BB Ball Bearing   \n",
      "\n",
      "  SpanishProductName FrenchProductName  StandardCost  FinishedGoodsFlag Color  \\\n",
      "0                                                NaN              False    NA   \n",
      "1                                                NaN              False    NA   \n",
      "2                                                NaN              False    NA   \n",
      "\n",
      "   SafetyStockLevel  ReorderPoint  ListPrice  Size SizeRange  Weight  \\\n",
      "0              1000           750        NaN  None        NA     NaN   \n",
      "1              1000           750        NaN  None        NA     NaN   \n",
      "2               800           600        NaN  None        NA     NaN   \n",
      "\n",
      "   DaysToManufacture ProductLine  DealerPrice Class Style ModelName  \\\n",
      "0                  0        None          NaN  None  None      None   \n",
      "1                  0        None          NaN  None  None      None   \n",
      "2                  1        None          NaN  None  None      None   \n",
      "\n",
      "                                          LargePhoto EnglishDescription  \\\n",
      "0  b'GIF89a\\xf0\\x00\\x95\\x00\\xf7\\x00\\x00\\x00\\x00\\x...               None   \n",
      "1  b'GIF89a\\xf0\\x00\\x95\\x00\\xf7\\x00\\x00\\x00\\x00\\x...               None   \n",
      "2  b'GIF89a\\xf0\\x00\\x95\\x00\\xf7\\x00\\x00\\x00\\x00\\x...               None   \n",
      "\n",
      "  FrenchDescription ChineseDescription ArabicDescription HebrewDescription  \\\n",
      "0              None               None              None              None   \n",
      "1              None               None              None              None   \n",
      "2              None               None              None              None   \n",
      "\n",
      "  ThaiDescription GermanDescription JapaneseDescription TurkishDescription  \\\n",
      "0            None              None                None               None   \n",
      "1            None              None                None               None   \n",
      "2            None              None                None               None   \n",
      "\n",
      "   StartDate EndDate   Status  \n",
      "0 2003-07-01     NaT  Current  \n",
      "1 2003-07-01     NaT  Current  \n",
      "2 2003-07-01     NaT  Current  \n"
     ]
    }
   ],
   "source": [
    "# Verificar que los datos en dim_product (postgres) y DimProduct (sqlserver) sean iguales\n",
    "\n",
    "# Extraer datos de ambas bases de datos\n",
    "df_postgres_product = pd.read_sql(\"SELECT * FROM dim_product ORDER BY productkey\", engine_postgres)\n",
    "df_sqlserver_product = pd.read_sql(\"SELECT * FROM DimProduct ORDER BY ProductKey\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL (dim_product): {len(df_postgres_product)}\")\n",
    "print(f\"Registros en SQL Server (DimProduct): {len(df_sqlserver_product)}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Normalizar nombres de columnas para comparación (SQL Server usa PascalCase, Postgres usa snake_case)\n",
    "df_sqlserver_normalized = df_sqlserver_product.copy()\n",
    "df_sqlserver_normalized.columns = df_sqlserver_normalized.columns.str.lower()\n",
    "\n",
    "# Verificar si tienen el mismo número de registros\n",
    "if len(df_postgres_product) != len(df_sqlserver_normalized):\n",
    "    print(f\"ADVERTENCIA: Diferente numero de registros!\")\n",
    "    print(f\"   PostgreSQL: {len(df_postgres_product)} registros\")\n",
    "    print(f\"   SQL Server: {len(df_sqlserver_normalized)} registros\")\n",
    "else:\n",
    "    print(f\"Mismo numero de registros: {len(df_postgres_product)}\")\n",
    "\n",
    "# Verificar columnas\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"COLUMNAS:\")\n",
    "print(f\"\\nPostgreSQL: {list(df_postgres_product.columns)}\")\n",
    "print(f\"\\nSQL Server: {list(df_sqlserver_product.columns)}\")\n",
    "\n",
    "# Comparar columnas comunes\n",
    "common_cols = set(df_postgres_product.columns) & set(df_sqlserver_normalized.columns)\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Columnas comunes para comparar: {len(common_cols)}\")\n",
    "print(f\"{sorted(common_cols)}\")\n",
    "\n",
    "# Lista para almacenar las filas con diferencias\n",
    "rows_with_differences = []\n",
    "\n",
    "# Realizar comparación detallada si tienen las mismas columnas\n",
    "if len(common_cols) > 0:\n",
    "    # Ordenar por clave primaria y resetear índice\n",
    "    df_pg_sorted = df_postgres_product.sort_values('productkey').reset_index(drop=True)\n",
    "    df_ss_sorted = df_sqlserver_normalized.sort_values('productkey').reset_index(drop=True)\n",
    "    \n",
    "    # Seleccionar solo columnas comunes\n",
    "    df_pg_compare = df_pg_sorted[sorted(common_cols)]\n",
    "    df_ss_compare = df_ss_sorted[sorted(common_cols)]\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"COMPARACION DE DATOS:\")\n",
    "    \n",
    "    # Comparar valores\n",
    "    differences_found = False\n",
    "    for col in sorted(common_cols):\n",
    "        try:\n",
    "            # Convertir a string para comparación más robusta (maneja NaN, tipos diferentes, etc.)\n",
    "            # Usar errors='ignore' para manejar problemas de encoding\n",
    "            pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"\\nDiferencias en columna '{col}': {diff_count} registros diferentes\")\n",
    "                \n",
    "                # Guardar información de diferencias\n",
    "                diff_mask = pg_values != ss_values\n",
    "                if diff_mask.any():\n",
    "                    print(f\"   Ejemplos (primeros 5):\")\n",
    "                    diff_indices = diff_mask[diff_mask].index[:5]\n",
    "                    for idx in diff_indices:\n",
    "                        pg_val = str(df_pg_compare.loc[idx, col])[:50]\n",
    "                        ss_val = str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')[:50]\n",
    "                        print(f\"   - Fila {idx}: PG='{pg_val}' vs SS='{ss_val}'\")\n",
    "                    \n",
    "                    # Agregar todas las filas con diferencias en esta columna\n",
    "                    for idx in diff_mask[diff_mask].index:\n",
    "                        row_diff = {\n",
    "                            'fila_index': idx,\n",
    "                            'productkey': df_pg_compare.loc[idx, 'productkey'],\n",
    "                            'columna_diferente': col,\n",
    "                            'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                            'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                        }\n",
    "                        rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError al comparar columna '{col}': {str(e)}\")\n",
    "            print(f\"   Tipo en PostgreSQL: {df_pg_compare[col].dtype}\")\n",
    "            print(f\"   Tipo en SQL Server: {df_ss_compare[col].dtype}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"\\nLOS DATOS SON IDENTICOS! Todas las columnas comunes coinciden perfectamente.\")\n",
    "    else:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"Se encontraron diferencias entre las tablas.\")\n",
    "        \n",
    "        # Exportar diferencias a CSV\n",
    "        if rows_with_differences:\n",
    "            df_differences = pd.DataFrame(rows_with_differences)\n",
    "            csv_filename = 'diferencias_dim_product.csv'\n",
    "            df_differences.to_csv(csv_filename, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nSe exportaron {len(rows_with_differences)} diferencias al archivo: {csv_filename}\")\n",
    "            print(f\"Total de filas unicas con diferencias: {df_differences['fila_index'].nunique()}\")\n",
    "            print(f\"\\nColumnas con diferencias:\")\n",
    "            print(df_differences['columna_diferente'].value_counts())\n",
    "else:\n",
    "    print(\"\\nNo se encontraron columnas comunes para comparar.\")\n",
    "\n",
    "# Mostrar muestra de datos\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"\\nMUESTRA DE DATOS (primeras 3 filas):\")\n",
    "print(\"\\nPostgreSQL (dim_product):\")\n",
    "print(df_postgres_product.head(3))\n",
    "print(\"\\nSQL Server (DimProduct):\")\n",
    "# Manejar posibles problemas de encoding en la visualización\n",
    "try:\n",
    "    print(df_sqlserver_product.head(3))\n",
    "except:\n",
    "    # Si hay problemas de encoding, mostrar con columnas específicas\n",
    "    print(\"(Nota: Algunos caracteres pueden no mostrarse correctamente debido a problemas de encoding)\")\n",
    "    for col in df_sqlserver_product.columns:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(df_sqlserver_product[col].head(3).apply(lambda x: str(x).encode('utf-8', errors='replace').decode('utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "bf77bc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 3652 | SQL Server: 3652\n",
      "Columnas comunes: 19\n",
      "LOS DATOS SON IDENTICOS!\n"
     ]
    }
   ],
   "source": [
    "# Comparar dim_date (postgres) vs DimDate (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM dim_date ORDER BY datekey\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM DimDate ORDER BY DateKey\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "if len(common_cols) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values('datekey').reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values('datekey').reset_index(drop=True)\n",
    "    \n",
    "    df_pg_compare = df_pg_sorted[sorted(common_cols)]\n",
    "    df_ss_compare = df_ss_sorted[sorted(common_cols)]\n",
    "    \n",
    "    differences_found = False\n",
    "    for col in sorted(common_cols):\n",
    "        try:\n",
    "            pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                \n",
    "                diff_mask = pg_values != ss_values\n",
    "                for idx in diff_mask[diff_mask].index:\n",
    "                    row_diff = {\n",
    "                        'tabla': 'dim_date',\n",
    "                        'fila_index': idx,\n",
    "                        'datekey': df_pg_compare.loc[idx, 'datekey'],\n",
    "                        'columna_diferente': col,\n",
    "                        'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                        'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                    }\n",
    "                    rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"Error en columna '{col}': {str(e)}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"LOS DATOS SON IDENTICOS!\")\n",
    "    else:\n",
    "        if rows_with_differences:\n",
    "            df_diff = pd.DataFrame(rows_with_differences)\n",
    "            csv_file = 'diferencias_dim_date.csv'\n",
    "            df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "            print(f\"Filas unicas con diferencias: {df_diff['fila_index'].nunique()}\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "1bd82e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 10 | SQL Server: 11\n",
      "Columnas comunes: 5\n",
      "\n",
      "ADVERTENCIA: Diferente cantidad de registros!\n",
      "Diferencia: 1 registros\n",
      "Claves solo en SQL Server: [11]\n",
      "\n",
      "Comparando 10 claves comunes...\n",
      "LOS DATOS SON IDENTICOS en las claves comunes!\n"
     ]
    }
   ],
   "source": [
    "# Comparar dim_salesterritory (postgres) vs DimSalesTerritory (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM dim_salesterritory ORDER BY salesterritorykey\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM DimSalesTerritory ORDER BY SalesTerritoryKey\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "# Verificar si tienen diferente cantidad de registros\n",
    "if len(df_pg) != len(df_ss):\n",
    "    print(f\"\\nADVERTENCIA: Diferente cantidad de registros!\")\n",
    "    print(f\"Diferencia: {abs(len(df_pg) - len(df_ss))} registros\")\n",
    "    \n",
    "    # Encontrar claves que están en una tabla pero no en la otra\n",
    "    pg_keys = set(df_pg['salesterritorykey'])\n",
    "    ss_keys = set(df_ss['salesterritorykey'])\n",
    "    \n",
    "    only_pg = pg_keys - ss_keys\n",
    "    only_ss = ss_keys - pg_keys\n",
    "    \n",
    "    if only_pg:\n",
    "        print(f\"\\nClaves solo en PostgreSQL: {sorted(only_pg)}\")\n",
    "    if only_ss:\n",
    "        print(f\"Claves solo en SQL Server: {sorted(only_ss)}\")\n",
    "\n",
    "if len(common_cols) > 0 and len(df_pg) > 0 and len(df_ss) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values('salesterritorykey').reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values('salesterritorykey').reset_index(drop=True)\n",
    "    \n",
    "    # Comparar solo las claves que existen en ambas tablas\n",
    "    common_keys = set(df_pg_sorted['salesterritorykey']) & set(df_ss_sorted['salesterritorykey'])\n",
    "    \n",
    "    if len(common_keys) > 0:\n",
    "        df_pg_compare = df_pg_sorted[df_pg_sorted['salesterritorykey'].isin(common_keys)].reset_index(drop=True)\n",
    "        df_ss_compare = df_ss_sorted[df_ss_sorted['salesterritorykey'].isin(common_keys)].reset_index(drop=True)\n",
    "        \n",
    "        print(f\"\\nComparando {len(common_keys)} claves comunes...\")\n",
    "        \n",
    "        differences_found = False\n",
    "        for col in sorted(common_cols):\n",
    "            try:\n",
    "                pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "                ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "                \n",
    "                if not pg_values.equals(ss_values):\n",
    "                    differences_found = True\n",
    "                    diff_count = (pg_values != ss_values).sum()\n",
    "                    print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                    \n",
    "                    diff_mask = pg_values != ss_values\n",
    "                    for idx in diff_mask[diff_mask].index:\n",
    "                        row_diff = {\n",
    "                            'tabla': 'dim_salesterritory',\n",
    "                            'fila_index': idx,\n",
    "                            'salesterritorykey': df_pg_compare.loc[idx, 'salesterritorykey'],\n",
    "                            'columna_diferente': col,\n",
    "                            'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                            'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                        }\n",
    "                        rows_with_differences.append(row_diff)\n",
    "            except Exception as e:\n",
    "                print(f\"Error en columna '{col}': {str(e)}\")\n",
    "        \n",
    "        if not differences_found:\n",
    "            print(\"LOS DATOS SON IDENTICOS en las claves comunes!\")\n",
    "        else:\n",
    "            if rows_with_differences:\n",
    "                df_diff = pd.DataFrame(rows_with_differences)\n",
    "                csv_file = 'diferencias_dim_salesterritory.csv'\n",
    "                df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "                print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "                print(f\"Filas unicas con diferencias: {df_diff['fila_index'].nunique()}\")\n",
    "    else:\n",
    "        print(\"\\nNo hay claves comunes para comparar\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "55048d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 10 | SQL Server: 10\n",
      "Columnas comunes: 3\n",
      "LOS DATOS SON IDENTICOS!\n"
     ]
    }
   ],
   "source": [
    "# Comparar dim_salesreason (postgres) vs DimSalesReason (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM dim_salesreason ORDER BY salesreasonkey\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM DimSalesReason ORDER BY SalesReasonKey\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "if len(common_cols) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values('salesreasonkey').reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values('salesreasonkey').reset_index(drop=True)\n",
    "    \n",
    "    df_pg_compare = df_pg_sorted[sorted(common_cols)]\n",
    "    df_ss_compare = df_ss_sorted[sorted(common_cols)]\n",
    "    \n",
    "    differences_found = False\n",
    "    for col in sorted(common_cols):\n",
    "        try:\n",
    "            pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                \n",
    "                diff_mask = pg_values != ss_values\n",
    "                for idx in diff_mask[diff_mask].index:\n",
    "                    row_diff = {\n",
    "                        'tabla': 'dim_salesreason',\n",
    "                        'fila_index': idx,\n",
    "                        'salesreasonkey': df_pg_compare.loc[idx, 'salesreasonkey'],\n",
    "                        'columna_diferente': col,\n",
    "                        'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                        'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                    }\n",
    "                    rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"Error en columna '{col}': {str(e)}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"LOS DATOS SON IDENTICOS!\")\n",
    "    else:\n",
    "        if rows_with_differences:\n",
    "            df_diff = pd.DataFrame(rows_with_differences)\n",
    "            csv_file = 'diferencias_dim_salesreason.csv'\n",
    "            df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "            print(f\"Filas unicas con diferencias: {df_diff['fila_index'].nunique()}\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "a86d9a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 16 | SQL Server: 16\n",
      "Columnas comunes: 4\n",
      "Diferencias en 'enddate': 16 registros\n",
      "Diferencias en 'startdate': 16 registros\n",
      "\n",
      "Exportadas 32 diferencias a: diferencias_dim_promotion.csv\n",
      "Filas unicas con diferencias: 16\n"
     ]
    }
   ],
   "source": [
    "# Comparar dim_promotion (postgres) vs DimPromotion (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM dim_promotion ORDER BY promotionkey\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM DimPromotion ORDER BY PromotionKey\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "if len(common_cols) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values('promotionkey').reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values('promotionkey').reset_index(drop=True)\n",
    "    \n",
    "    df_pg_compare = df_pg_sorted[sorted(common_cols)]\n",
    "    df_ss_compare = df_ss_sorted[sorted(common_cols)]\n",
    "    \n",
    "    differences_found = False\n",
    "    for col in sorted(common_cols):\n",
    "        try:\n",
    "            pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                \n",
    "                diff_mask = pg_values != ss_values\n",
    "                for idx in diff_mask[diff_mask].index:\n",
    "                    row_diff = {\n",
    "                        'tabla': 'dim_promotion',\n",
    "                        'fila_index': idx,\n",
    "                        'promotionkey': df_pg_compare.loc[idx, 'promotionkey'],\n",
    "                        'columna_diferente': col,\n",
    "                        'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                        'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                    }\n",
    "                    rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"Error en columna '{col}': {str(e)}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"LOS DATOS SON IDENTICOS!\")\n",
    "    else:\n",
    "        if rows_with_differences:\n",
    "            df_diff = pd.DataFrame(rows_with_differences)\n",
    "            csv_file = 'diferencias_dim_promotion.csv'\n",
    "            df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "            print(f\"Filas unicas con diferencias: {df_diff['fila_index'].nunique()}\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "e5b83ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 290 | SQL Server: 296\n",
      "Columnas comunes: 29\n",
      "\n",
      "ADVERTENCIA: Diferente cantidad de registros!\n",
      "Diferencia: 6 registros\n",
      "Claves solo en SQL Server: [291, 292, 293, 294, 295, 296]\n",
      "\n",
      "Comparando 290 claves comunes...\n",
      "Diferencias en 'baserate': 267 registros\n",
      "Diferencias en 'birthdate': 290 registros\n",
      "Diferencias en 'departmentname': 152 registros\n",
      "Diferencias en 'emailaddress': 288 registros\n",
      "Diferencias en 'emergencycontactname': 288 registros\n",
      "Diferencias en 'emergencycontactphone': 288 registros\n",
      "Diferencias en 'employeenationalidalternatekey': 288 registros\n",
      "Diferencias en 'enddate': 10 registros\n",
      "Diferencias en 'firstname': 287 registros\n",
      "Diferencias en 'gender': 118 registros\n",
      "Diferencias en 'hiredate': 290 registros\n",
      "Diferencias en 'lastname': 287 registros\n",
      "Diferencias en 'loginid': 288 registros\n",
      "Diferencias en 'maritalstatus': 147 registros\n",
      "Diferencias en 'middlename': 278 registros\n",
      "Diferencias en 'payfrequency': 132 registros\n",
      "Diferencias en 'phone': 288 registros\n",
      "Diferencias en 'salariedflag': 60 registros\n",
      "Diferencias en 'salespersonflag': 9 registros\n",
      "Diferencias en 'salesterritorykey': 16 registros\n",
      "Diferencias en 'sickleavehours': 286 registros\n",
      "Diferencias en 'startdate': 290 registros\n",
      "Diferencias en 'status': 289 registros\n",
      "Diferencias en 'title': 268 registros\n",
      "Diferencias en 'vacationhours': 286 registros\n",
      "\n",
      "Se encontraron diferencias en las claves comunes\n",
      "\n",
      "Exportadas 5496 diferencias a: diferencias_dim_employee.csv\n",
      "Filas unicas con diferencias: 290\n",
      "Registros solo en una BD: 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Comparar dim_employee (postgres) vs DimEmployee (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM dim_employee ORDER BY employeekey\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM DimEmployee ORDER BY EmployeeKey\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "# Verificar si tienen diferente cantidad de registros\n",
    "if len(df_pg) != len(df_ss):\n",
    "    print(f\"\\nADVERTENCIA: Diferente cantidad de registros!\")\n",
    "    print(f\"Diferencia: {abs(len(df_pg) - len(df_ss))} registros\")\n",
    "    \n",
    "    # Encontrar claves que están en una tabla pero no en la otra\n",
    "    pg_keys = set(df_pg['employeekey'])\n",
    "    ss_keys = set(df_ss['employeekey'])\n",
    "    \n",
    "    only_pg = pg_keys - ss_keys\n",
    "    only_ss = ss_keys - pg_keys\n",
    "    \n",
    "    if only_pg:\n",
    "        print(f\"\\nClaves solo en PostgreSQL: {sorted(only_pg)}\")\n",
    "        # Agregar registros solo en PostgreSQL al archivo de diferencias\n",
    "        for key in only_pg:\n",
    "            rows_with_differences.append({\n",
    "                'tabla': 'dim_employee',\n",
    "                'fila_index': -1,\n",
    "                'employeekey': key,\n",
    "                'columna_diferente': 'REGISTRO_COMPLETO',\n",
    "                'valor_postgres': 'EXISTE',\n",
    "                'valor_sqlserver': 'NO_EXISTE'\n",
    "            })\n",
    "    \n",
    "    if only_ss:\n",
    "        print(f\"Claves solo en SQL Server: {sorted(only_ss)}\")\n",
    "        # Agregar registros solo en SQL Server al archivo de diferencias\n",
    "        for key in only_ss:\n",
    "            rows_with_differences.append({\n",
    "                'tabla': 'dim_employee',\n",
    "                'fila_index': -1,\n",
    "                'employeekey': key,\n",
    "                'columna_diferente': 'REGISTRO_COMPLETO',\n",
    "                'valor_postgres': 'NO_EXISTE',\n",
    "                'valor_sqlserver': 'EXISTE'\n",
    "            })\n",
    "\n",
    "if len(common_cols) > 0 and len(df_pg) > 0 and len(df_ss) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values('employeekey').reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values('employeekey').reset_index(drop=True)\n",
    "    \n",
    "    # Comparar solo las claves que existen en ambas tablas\n",
    "    common_keys = set(df_pg_sorted['employeekey']) & set(df_ss_sorted['employeekey'])\n",
    "    \n",
    "    if len(common_keys) > 0:\n",
    "        df_pg_compare = df_pg_sorted[df_pg_sorted['employeekey'].isin(common_keys)].reset_index(drop=True)\n",
    "        df_ss_compare = df_ss_sorted[df_ss_sorted['employeekey'].isin(common_keys)].reset_index(drop=True)\n",
    "        \n",
    "        print(f\"\\nComparando {len(common_keys)} claves comunes...\")\n",
    "        \n",
    "        differences_found = False\n",
    "        for col in sorted(common_cols):\n",
    "            try:\n",
    "                pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "                ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "                \n",
    "                if not pg_values.equals(ss_values):\n",
    "                    differences_found = True\n",
    "                    diff_count = (pg_values != ss_values).sum()\n",
    "                    print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                    \n",
    "                    diff_mask = pg_values != ss_values\n",
    "                    for idx in diff_mask[diff_mask].index:\n",
    "                        row_diff = {\n",
    "                            'tabla': 'dim_employee',\n",
    "                            'fila_index': idx,\n",
    "                            'employeekey': df_pg_compare.loc[idx, 'employeekey'],\n",
    "                            'columna_diferente': col,\n",
    "                            'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                            'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                        }\n",
    "                        rows_with_differences.append(row_diff)\n",
    "            except Exception as e:\n",
    "                print(f\"Error en columna '{col}': {str(e)}\")\n",
    "        \n",
    "        if not differences_found:\n",
    "            print(\"LOS DATOS SON IDENTICOS en las claves comunes!\")\n",
    "        else:\n",
    "            print(f\"\\nSe encontraron diferencias en las claves comunes\")\n",
    "    else:\n",
    "        print(\"\\nNo hay claves comunes para comparar\")\n",
    "\n",
    "# Exportar diferencias a CSV (si las hay)\n",
    "if rows_with_differences:\n",
    "    df_diff = pd.DataFrame(rows_with_differences)\n",
    "    csv_file = 'diferencias_dim_employee.csv'\n",
    "    df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "    print(f\"Filas unicas con diferencias: {df_diff[df_diff['fila_index'] != -1]['fila_index'].nunique() if any(df_diff['fila_index'] != -1) else 0}\")\n",
    "    print(f\"Registros solo en una BD: {len(df_diff[df_diff['fila_index'] == -1])}\")\n",
    "else:\n",
    "    print(\"\\nNo se encontraron diferencias\")\n",
    "    \n",
    "print(\"\\nNo hay columnas comunes para comparar\" if len(common_cols) == 0 else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "36359126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 701 | SQL Server: 701\n",
      "Columnas comunes: 16\n",
      "Diferencias en 'addressline1': 26 registros\n",
      "Diferencias en 'annualrevenue': 701 registros\n",
      "Diferencias en 'annualsales': 701 registros\n",
      "Diferencias en 'businesstype': 470 registros\n",
      "Diferencias en 'geographykey': 95 registros\n",
      "Diferencias en 'minpaymentamount': 191 registros\n",
      "Diferencias en 'minpaymenttype': 569 registros\n",
      "Diferencias en 'phone': 38 registros\n",
      "Diferencias en 'resellername': 4 registros\n",
      "Diferencias en 'yearopened': 701 registros\n",
      "\n",
      "Exportadas 3496 diferencias a: diferencias_dim_reseller.csv\n",
      "Filas unicas con diferencias: 701\n"
     ]
    }
   ],
   "source": [
    "# Comparar dim_reseller (postgres) vs DimReseller (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM dim_reseller ORDER BY resellerkey\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM DimReseller ORDER BY ResellerKey\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "if len(common_cols) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values('resellerkey').reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values('resellerkey').reset_index(drop=True)\n",
    "    \n",
    "    df_pg_compare = df_pg_sorted[sorted(common_cols)]\n",
    "    df_ss_compare = df_ss_sorted[sorted(common_cols)]\n",
    "    \n",
    "    differences_found = False\n",
    "    for col in sorted(common_cols):\n",
    "        try:\n",
    "            pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                \n",
    "                diff_mask = pg_values != ss_values\n",
    "                for idx in diff_mask[diff_mask].index:\n",
    "                    row_diff = {\n",
    "                        'tabla': 'dim_reseller',\n",
    "                        'fila_index': idx,\n",
    "                        'resellerkey': df_pg_compare.loc[idx, 'resellerkey'],\n",
    "                        'columna_diferente': col,\n",
    "                        'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                        'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                    }\n",
    "                    rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"Error en columna '{col}': {str(e)}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"LOS DATOS SON IDENTICOS!\")\n",
    "    else:\n",
    "        if rows_with_differences:\n",
    "            df_diff = pd.DataFrame(rows_with_differences)\n",
    "            csv_file = 'diferencias_dim_reseller.csv'\n",
    "            df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "            print(f\"Filas unicas con diferencias: {df_diff['fila_index'].nunique()}\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "84ced963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 64515 | SQL Server: 64515\n",
      "Columnas comunes: 3\n",
      "LOS DATOS SON IDENTICOS!\n"
     ]
    }
   ],
   "source": [
    "# Comparar fact_internet_sales_reason (postgres) vs FactInternetSalesReason (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM fact_internet_sales_reason ORDER BY salesordernumber, salesorderlinenumber, salesreasonid\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM FactInternetSalesReason ORDER BY SalesOrderNumber, SalesOrderLineNumber, SalesReasonKey\", engine_sqlserver)\n",
    "\n",
    "# Rename salesreasonid to salesreasonkey in PostgreSQL dataframe for consistency\n",
    "df_pg.rename(columns={'salesreasonid': 'salesreasonkey'}, inplace=True)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "if len(common_cols) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values(['salesordernumber', 'salesorderlinenumber', 'salesreasonkey']).reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values(['salesordernumber', 'salesorderlinenumber', 'salesreasonkey']).reset_index(drop=True)\n",
    "    \n",
    "    df_pg_compare = df_pg_sorted[sorted(common_cols)]\n",
    "    df_ss_compare = df_ss_sorted[sorted(common_cols)]\n",
    "    \n",
    "    differences_found = False\n",
    "    for col in sorted(common_cols):\n",
    "        try:\n",
    "            pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                \n",
    "                diff_mask = pg_values != ss_values\n",
    "                for idx in diff_mask[diff_mask].index[:100]:  # Limitar a 100 diferencias por columna\n",
    "                    row_diff = {\n",
    "                        'tabla': 'fact_internet_sales_reason',\n",
    "                        'fila_index': idx,\n",
    "                        'salesordernumber': df_pg_compare.loc[idx, 'salesordernumber'],\n",
    "                        'salesorderlinenumber': df_pg_compare.loc[idx, 'salesorderlinenumber'],\n",
    "                        'salesreasonkey': df_pg_compare.loc[idx, 'salesreasonkey'],\n",
    "                        'columna_diferente': col,\n",
    "                        'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                        'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                    }\n",
    "                    rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"Error en columna '{col}': {str(e)}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"LOS DATOS SON IDENTICOS!\")\n",
    "    else:\n",
    "        if rows_with_differences:\n",
    "            df_diff = pd.DataFrame(rows_with_differences)\n",
    "            csv_file = 'diferencias_fact_internet_sales_reason.csv'\n",
    "            df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "            print(f\"Filas unicas con diferencias: {df_diff['fila_index'].nunique()}\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "b34f73b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 60398 | SQL Server: 60398\n",
      "Columnas comunes: 25\n",
      "Diferencias en 'duedate': 60398 registros\n",
      "Diferencias en 'duedatekey': 60398 registros\n",
      "Diferencias en 'extendedamount': 1075 registros\n",
      "Diferencias en 'freight': 50730 registros\n",
      "Diferencias en 'orderdate': 60398 registros\n",
      "Diferencias en 'orderdatekey': 60398 registros\n",
      "Diferencias en 'productkey': 16605 registros\n",
      "Diferencias en 'productstandardcost': 2449 registros\n",
      "Diferencias en 'revisionnumber': 60398 registros\n",
      "Diferencias en 'salesamount': 1075 registros\n",
      "Diferencias en 'shipdate': 60398 registros\n",
      "Diferencias en 'shipdatekey': 60398 registros\n",
      "Diferencias en 'taxamt': 50730 registros\n",
      "Diferencias en 'totalproductcost': 2449 registros\n",
      "Diferencias en 'unitprice': 1075 registros\n",
      "\n",
      "Exportadas 1500 diferencias a: diferencias_fact_internet_sales.csv\n",
      "Filas unicas con diferencias: 491\n"
     ]
    }
   ],
   "source": [
    "# Comparar fact_internet_sales (postgres) vs FactInternetSales (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM fact_internet_sales ORDER BY salesordernumber, salesorderlinenumber\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM FactInternetSales ORDER BY SalesOrderNumber, SalesOrderLineNumber\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "if len(common_cols) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values(['salesordernumber', 'salesorderlinenumber']).reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values(['salesordernumber', 'salesorderlinenumber']).reset_index(drop=True)\n",
    "    \n",
    "    df_pg_compare = df_pg_sorted[sorted(common_cols)]\n",
    "    df_ss_compare = df_ss_sorted[sorted(common_cols)]\n",
    "    \n",
    "    differences_found = False\n",
    "    for col in sorted(common_cols):\n",
    "        try:\n",
    "            pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                \n",
    "                diff_mask = pg_values != ss_values\n",
    "                for idx in diff_mask[diff_mask].index[:100]:  # Limitar a 100 diferencias por columna\n",
    "                    row_diff = {\n",
    "                        'tabla': 'fact_internet_sales',\n",
    "                        'fila_index': idx,\n",
    "                        'salesordernumber': df_pg_compare.loc[idx, 'salesordernumber'],\n",
    "                        'salesorderlinenumber': df_pg_compare.loc[idx, 'salesorderlinenumber'],\n",
    "                        'columna_diferente': col,\n",
    "                        'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                        'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                    }\n",
    "                    rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"Error en columna '{col}': {str(e)}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"LOS DATOS SON IDENTICOS!\")\n",
    "    else:\n",
    "        if rows_with_differences:\n",
    "            df_diff = pd.DataFrame(rows_with_differences)\n",
    "            csv_file = 'diferencias_fact_internet_sales.csv'\n",
    "            df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "            print(f\"Filas unicas con diferencias: {df_diff['fila_index'].nunique()}\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "6796a9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 655 | SQL Server: 655\n",
      "Columnas comunes: 8\n",
      "Diferencias en 'city': 12 registros\n",
      "Diferencias en 'ipaddresslocator': 402 registros\n",
      "Diferencias en 'postalcode': 85 registros\n",
      "Diferencias en 'stateprovincecode': 565 registros\n",
      "\n",
      "Exportadas 1064 diferencias a: diferencias_dim_geography.csv\n",
      "Filas unicas con diferencias: 601\n"
     ]
    }
   ],
   "source": [
    "# Comparar dim_geography (postgres) vs DimGeography (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM dim_geography ORDER BY geographykey\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM DimGeography ORDER BY GeographyKey\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "if len(common_cols) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values('geographykey').reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values('geographykey').reset_index(drop=True)\n",
    "    \n",
    "    df_pg_compare = df_pg_sorted[sorted(common_cols)]\n",
    "    df_ss_compare = df_ss_sorted[sorted(common_cols)]\n",
    "    \n",
    "    differences_found = False\n",
    "    for col in sorted(common_cols):\n",
    "        try:\n",
    "            pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                \n",
    "                diff_mask = pg_values != ss_values\n",
    "                for idx in diff_mask[diff_mask].index:\n",
    "                    row_diff = {\n",
    "                        'tabla': 'dim_geography',\n",
    "                        'fila_index': idx,\n",
    "                        'geographykey': df_pg_compare.loc[idx, 'geographykey'],\n",
    "                        'columna_diferente': col,\n",
    "                        'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                        'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                    }\n",
    "                    rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"Error en columna '{col}': {str(e)}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"LOS DATOS SON IDENTICOS!\")\n",
    "    else:\n",
    "        if rows_with_differences:\n",
    "            df_diff = pd.DataFrame(rows_with_differences)\n",
    "            csv_file = 'diferencias_dim_geography.csv'\n",
    "            df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "            print(f\"Filas unicas con diferencias: {df_diff['fila_index'].nunique()}\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "33231f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 18484 | SQL Server: 18484\n",
      "Columnas comunes: 21\n",
      "Diferencias en 'addressline1': 2 registros\n",
      "Diferencias en 'birthdate': 18484 registros\n",
      "Diferencias en 'datefirstpurchase': 18484 registros\n",
      "Diferencias en 'geographykey': 1770 registros\n",
      "Diferencias en 'yearlyincome': 18484 registros\n",
      "\n",
      "Exportadas 57224 diferencias a: diferencias_dim_customer.csv\n",
      "Filas unicas con diferencias: 18484\n"
     ]
    }
   ],
   "source": [
    "# Comparar dim_customer (postgres) vs DimCustomer (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM dim_customer ORDER BY customerkey\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM DimCustomer ORDER BY CustomerKey\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "if len(common_cols) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values('customerkey').reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values('customerkey').reset_index(drop=True)\n",
    "    \n",
    "    df_pg_compare = df_pg_sorted[sorted(common_cols)]\n",
    "    df_ss_compare = df_ss_sorted[sorted(common_cols)]\n",
    "    \n",
    "    differences_found = False\n",
    "    for col in sorted(common_cols):\n",
    "        try:\n",
    "            pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                \n",
    "                diff_mask = pg_values != ss_values\n",
    "                for idx in diff_mask[diff_mask].index:\n",
    "                    row_diff = {\n",
    "                        'tabla': 'dim_customer',\n",
    "                        'fila_index': idx,\n",
    "                        'customerkey': df_pg_compare.loc[idx, 'customerkey'],\n",
    "                        'columna_diferente': col,\n",
    "                        'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                        'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                    }\n",
    "                    rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"Error en columna '{col}': {str(e)}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"LOS DATOS SON IDENTICOS!\")\n",
    "    else:\n",
    "        if rows_with_differences:\n",
    "            df_diff = pd.DataFrame(rows_with_differences)\n",
    "            csv_file = 'diferencias_dim_customer.csv'\n",
    "            df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "            print(f\"Filas unicas con diferencias: {df_diff['fila_index'].nunique()}\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "5e984182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 105 | SQL Server: 105\n",
      "Columnas comunes: 3\n",
      "Diferencias en 'currencyname': 105 registros\n",
      "\n",
      "Exportadas 105 diferencias a: diferencias_dim_currency.csv\n",
      "Filas unicas con diferencias: 105\n"
     ]
    }
   ],
   "source": [
    "# Comparar dim_currency (postgres) vs DimCurrency (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM dim_currency ORDER BY currencykey\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM DimCurrency ORDER BY CurrencyKey\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "if len(common_cols) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values('currencykey').reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values('currencykey').reset_index(drop=True)\n",
    "    \n",
    "    df_pg_compare = df_pg_sorted[sorted(common_cols)]\n",
    "    df_ss_compare = df_ss_sorted[sorted(common_cols)]\n",
    "    \n",
    "    differences_found = False\n",
    "    for col in sorted(common_cols):\n",
    "        try:\n",
    "            pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                \n",
    "                diff_mask = pg_values != ss_values\n",
    "                for idx in diff_mask[diff_mask].index:\n",
    "                    row_diff = {\n",
    "                        'tabla': 'dim_currency',\n",
    "                        'fila_index': idx,\n",
    "                        'currencykey': df_pg_compare.loc[idx, 'currencykey'],\n",
    "                        'columna_diferente': col,\n",
    "                        'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                        'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                    }\n",
    "                    rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"Error en columna '{col}': {str(e)}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"LOS DATOS SON IDENTICOS!\")\n",
    "    else:\n",
    "        if rows_with_differences:\n",
    "            df_diff = pd.DataFrame(rows_with_differences)\n",
    "            csv_file = 'diferencias_dim_currency.csv'\n",
    "            df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "            print(f\"Filas unicas con diferencias: {df_diff['fila_index'].nunique()}\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "e4329fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateKey</th>\n",
       "      <th>FullDateAlternateKey</th>\n",
       "      <th>DayNumberOfWeek</th>\n",
       "      <th>EnglishDayNameOfWeek</th>\n",
       "      <th>SpanishDayNameOfWeek</th>\n",
       "      <th>FrenchDayNameOfWeek</th>\n",
       "      <th>DayNumberOfMonth</th>\n",
       "      <th>DayNumberOfYear</th>\n",
       "      <th>WeekNumberOfYear</th>\n",
       "      <th>EnglishMonthName</th>\n",
       "      <th>SpanishMonthName</th>\n",
       "      <th>FrenchMonthName</th>\n",
       "      <th>MonthNumberOfYear</th>\n",
       "      <th>CalendarQuarter</th>\n",
       "      <th>CalendarYear</th>\n",
       "      <th>CalendarSemester</th>\n",
       "      <th>FiscalQuarter</th>\n",
       "      <th>FiscalYear</th>\n",
       "      <th>FiscalSemester</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20050101</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>7</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Sábado</td>\n",
       "      <td>Samedi</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>Enero</td>\n",
       "      <td>Janvier</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20050102</td>\n",
       "      <td>2005-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>Domingo</td>\n",
       "      <td>Dimanche</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>January</td>\n",
       "      <td>Enero</td>\n",
       "      <td>Janvier</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20050103</td>\n",
       "      <td>2005-01-03</td>\n",
       "      <td>2</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Lunes</td>\n",
       "      <td>Lundi</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>January</td>\n",
       "      <td>Enero</td>\n",
       "      <td>Janvier</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20050104</td>\n",
       "      <td>2005-01-04</td>\n",
       "      <td>3</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Martes</td>\n",
       "      <td>Mardi</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>January</td>\n",
       "      <td>Enero</td>\n",
       "      <td>Janvier</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20050105</td>\n",
       "      <td>2005-01-05</td>\n",
       "      <td>4</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Miércoles</td>\n",
       "      <td>Mercredi</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>January</td>\n",
       "      <td>Enero</td>\n",
       "      <td>Janvier</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3647</th>\n",
       "      <td>20141227</td>\n",
       "      <td>2014-12-27</td>\n",
       "      <td>7</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Sábado</td>\n",
       "      <td>Samedi</td>\n",
       "      <td>27</td>\n",
       "      <td>361</td>\n",
       "      <td>52</td>\n",
       "      <td>December</td>\n",
       "      <td>Diciembre</td>\n",
       "      <td>Décembre</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3648</th>\n",
       "      <td>20141228</td>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>Domingo</td>\n",
       "      <td>Dimanche</td>\n",
       "      <td>28</td>\n",
       "      <td>362</td>\n",
       "      <td>53</td>\n",
       "      <td>December</td>\n",
       "      <td>Diciembre</td>\n",
       "      <td>Décembre</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>20141229</td>\n",
       "      <td>2014-12-29</td>\n",
       "      <td>2</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Lunes</td>\n",
       "      <td>Lundi</td>\n",
       "      <td>29</td>\n",
       "      <td>363</td>\n",
       "      <td>53</td>\n",
       "      <td>December</td>\n",
       "      <td>Diciembre</td>\n",
       "      <td>Décembre</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650</th>\n",
       "      <td>20141230</td>\n",
       "      <td>2014-12-30</td>\n",
       "      <td>3</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Martes</td>\n",
       "      <td>Mardi</td>\n",
       "      <td>30</td>\n",
       "      <td>364</td>\n",
       "      <td>53</td>\n",
       "      <td>December</td>\n",
       "      <td>Diciembre</td>\n",
       "      <td>Décembre</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651</th>\n",
       "      <td>20141231</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>4</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Miércoles</td>\n",
       "      <td>Mercredi</td>\n",
       "      <td>31</td>\n",
       "      <td>365</td>\n",
       "      <td>53</td>\n",
       "      <td>December</td>\n",
       "      <td>Diciembre</td>\n",
       "      <td>Décembre</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3652 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       DateKey FullDateAlternateKey  DayNumberOfWeek EnglishDayNameOfWeek  \\\n",
       "0     20050101           2005-01-01                7             Saturday   \n",
       "1     20050102           2005-01-02                1               Sunday   \n",
       "2     20050103           2005-01-03                2               Monday   \n",
       "3     20050104           2005-01-04                3              Tuesday   \n",
       "4     20050105           2005-01-05                4            Wednesday   \n",
       "...        ...                  ...              ...                  ...   \n",
       "3647  20141227           2014-12-27                7             Saturday   \n",
       "3648  20141228           2014-12-28                1               Sunday   \n",
       "3649  20141229           2014-12-29                2               Monday   \n",
       "3650  20141230           2014-12-30                3              Tuesday   \n",
       "3651  20141231           2014-12-31                4            Wednesday   \n",
       "\n",
       "     SpanishDayNameOfWeek FrenchDayNameOfWeek  DayNumberOfMonth  \\\n",
       "0                  Sábado              Samedi                 1   \n",
       "1                 Domingo            Dimanche                 2   \n",
       "2                   Lunes               Lundi                 3   \n",
       "3                  Martes               Mardi                 4   \n",
       "4               Miércoles            Mercredi                 5   \n",
       "...                   ...                 ...               ...   \n",
       "3647               Sábado              Samedi                27   \n",
       "3648              Domingo            Dimanche                28   \n",
       "3649                Lunes               Lundi                29   \n",
       "3650               Martes               Mardi                30   \n",
       "3651            Miércoles            Mercredi                31   \n",
       "\n",
       "      DayNumberOfYear  WeekNumberOfYear EnglishMonthName SpanishMonthName  \\\n",
       "0                   1                 1          January            Enero   \n",
       "1                   2                 2          January            Enero   \n",
       "2                   3                 2          January            Enero   \n",
       "3                   4                 2          January            Enero   \n",
       "4                   5                 2          January            Enero   \n",
       "...               ...               ...              ...              ...   \n",
       "3647              361                52         December        Diciembre   \n",
       "3648              362                53         December        Diciembre   \n",
       "3649              363                53         December        Diciembre   \n",
       "3650              364                53         December        Diciembre   \n",
       "3651              365                53         December        Diciembre   \n",
       "\n",
       "     FrenchMonthName  MonthNumberOfYear  CalendarQuarter  CalendarYear  \\\n",
       "0            Janvier                  1                1          2005   \n",
       "1            Janvier                  1                1          2005   \n",
       "2            Janvier                  1                1          2005   \n",
       "3            Janvier                  1                1          2005   \n",
       "4            Janvier                  1                1          2005   \n",
       "...              ...                ...              ...           ...   \n",
       "3647        Décembre                 12                4          2014   \n",
       "3648        Décembre                 12                4          2014   \n",
       "3649        Décembre                 12                4          2014   \n",
       "3650        Décembre                 12                4          2014   \n",
       "3651        Décembre                 12                4          2014   \n",
       "\n",
       "      CalendarSemester  FiscalQuarter  FiscalYear  FiscalSemester  \n",
       "0                    1              3        2005               2  \n",
       "1                    1              3        2005               2  \n",
       "2                    1              3        2005               2  \n",
       "3                    1              3        2005               2  \n",
       "4                    1              3        2005               2  \n",
       "...                ...            ...         ...             ...  \n",
       "3647                 2              2        2014               1  \n",
       "3648                 2              2        2014               1  \n",
       "3649                 2              2        2014               1  \n",
       "3650                 2              2        2014               1  \n",
       "3651                 2              2        2014               1  \n",
       "\n",
       "[3652 rows x 19 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pg = pd.read_sql(\"SELECT * FROM DimDate ORDER BY datekey\", engine_sqlserver)\n",
    "df_pg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
