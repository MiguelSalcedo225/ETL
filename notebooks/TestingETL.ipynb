{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "511949af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio de trabajo: /home/paelsam/Documents/Ciencia de Datos/ETL/notebooks\n"
     ]
    }
   ],
   "source": [
    "# Establecer directorio de trabajo para guardar archivos CSV\n",
    "import os\n",
    "os.chdir('/home/paelsam/Documents/Ciencia de Datos/ETL/notebooks')\n",
    "print(f\"Directorio de trabajo: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6af647b",
   "metadata": {},
   "source": [
    "## 1. Importar librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3259e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "from sqlalchemy import create_engine, text, inspect\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44cf277",
   "metadata": {},
   "source": [
    "## 2. Cargar configuración desde config.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90b367f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuración PostgreSQL: {'drivername': 'postgresql', 'dbname': 'prueba', 'user': 'postgres', 'password': 'postgres', 'host': 'localhost', 'port': 5432}\n",
      "\n",
      "Configuración SQL Server: {'drivername': 'mssql+pyodbc', 'dbname': 'AdventureWorksDW2022', 'user': 'sa', 'password': 'r00t.R00T', 'host': 'localhost', 'port': 1433, 'driver': 'FreeTDS'}\n"
     ]
    }
   ],
   "source": [
    "# Cargar configuración\n",
    "with open('../config.yml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Obtener configuraciones específicas\n",
    "config_postgres = config['ETL_PRO']\n",
    "config_sqlserver = config['SQL_SERVER_DW']\n",
    "\n",
    "print(\"Configuración PostgreSQL:\", config_postgres)\n",
    "print(\"\\nConfiguración SQL Server:\", config_sqlserver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245e89c9",
   "metadata": {},
   "source": [
    "## 3. Conexión a PostgreSQL (ETL_PRO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35715129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectado exitosamente a PostgreSQL\n",
      "Versión: PostgreSQL 17.6 (Debian 17.6-2.pgdg13+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 14.2.0-19) 14.2.0, 64-bit\n"
     ]
    }
   ],
   "source": [
    "# Construir URL de conexión para PostgreSQL\n",
    "url_postgres = (\n",
    "    f\"{config_postgres['drivername']}://\"\n",
    "    f\"{config_postgres['user']}:{config_postgres['password']}@\"\n",
    "    f\"{config_postgres['host']}:{config_postgres['port']}/\"\n",
    "    f\"{config_postgres['dbname']}\"\n",
    ")\n",
    "\n",
    "# Crear engine de SQLAlchemy para PostgreSQL\n",
    "engine_postgres = create_engine(url_postgres)\n",
    "\n",
    "# Verificar conexión\n",
    "try:\n",
    "    with engine_postgres.connect() as conn:\n",
    "        result = conn.execute(text(\"SELECT version();\"))\n",
    "        version = result.fetchone()\n",
    "        print(\"Conectado exitosamente a PostgreSQL\")\n",
    "        print(f\"Versión: {version[0]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al conectar a PostgreSQL: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90e3c4d",
   "metadata": {},
   "source": [
    "## 4. Conexión a SQL Server (AdventureWorksDW2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9133f82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectado exitosamente a SQL Server\n",
      "Versión: Microsoft SQL Server 2022 (RTM-CU21) (KB5065865) - 16.0.4215.2 (X64) \n",
      "\tAug 11 2025 13:24:21 \n",
      "\tCopyri...\n"
     ]
    }
   ],
   "source": [
    "# Construir URL de conexión para SQL Server\n",
    "# Nota: Asegúrate de tener instalado pyodbc y el driver ODBC para SQL Server\n",
    "url_sqlserver = (\n",
    "    f\"{config_sqlserver['drivername']}://\"\n",
    "    f\"{config_sqlserver['user']}:{config_sqlserver['password']}@\"\n",
    "    f\"{config_sqlserver['host']}:{config_sqlserver['port']}/\"\n",
    "    f\"{config_sqlserver['dbname']}\"\n",
    "    f\"?driver={config_sqlserver['driver'].replace(' ', '+')}\"\n",
    ")\n",
    "\n",
    "# Crear engine de SQLAlchemy para SQL Server\n",
    "engine_sqlserver = create_engine(url_sqlserver)\n",
    "\n",
    "# Verificar conexión\n",
    "try:\n",
    "    with engine_sqlserver.connect() as conn:\n",
    "        result = conn.execute(text(\"SELECT @@VERSION;\"))\n",
    "        version = result.fetchone()\n",
    "        print(\"Conectado exitosamente a SQL Server\")\n",
    "        print(f\"Versión: {version[0][:100]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al conectar a SQL Server: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6c2689",
   "metadata": {},
   "source": [
    "## 5. Ejemplo: Listar tablas en ambas bases de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f21045c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "TABLAS EN POSTGRESQL (ETL_PRO)\n",
      "==================================================\n",
      "1. dim_salesreason\n",
      "2. fact_internet_sales_reason\n",
      "3. dim_geography\n",
      "4. dim_customer\n",
      "5. dim_employee\n",
      "6. dim_salesterritory\n",
      "7. dim_reseller\n",
      "8. dim_product\n",
      "9. fact_internet_sales\n",
      "10. dim_promotion\n",
      "11. dim_currency\n",
      "12. dim_date\n",
      "13. fact_reseller_sales\n",
      "\n",
      "Total: 13 tablas\n",
      "\n",
      "==================================================\n",
      "TABLAS EN SQL SERVER (AdventureWorksDW2022)\n",
      "==================================================\n",
      "1. AdventureWorksDWBuildVersion\n",
      "2. DatabaseLog\n",
      "3. DimAccount\n",
      "4. DimCurrency\n",
      "5. DimCustomer\n",
      "6. DimDate\n",
      "7. DimDepartmentGroup\n",
      "8. DimEmployee\n",
      "9. DimGeography\n",
      "10. DimOrganization\n",
      "11. DimProduct\n",
      "12. DimProductCategory\n",
      "13. DimProductSubcategory\n",
      "14. DimPromotion\n",
      "15. DimReseller\n",
      "16. DimSalesReason\n",
      "17. DimSalesTerritory\n",
      "18. DimScenario\n",
      "19. FactAdditionalInternationalProductDescription\n",
      "20. FactCallCenter\n",
      "21. FactCurrencyRate\n",
      "22. FactFinance\n",
      "23. FactInternetSales\n",
      "24. FactInternetSalesReason\n",
      "25. FactProductInventory\n",
      "26. FactResellerSales\n",
      "27. FactSalesQuota\n",
      "28. FactSurveyResponse\n",
      "29. NewFactCurrencyRate\n",
      "30. ProspectiveBuyer\n",
      "31. sysdiagrams\n",
      "\n",
      "Total: 31 tablas\n"
     ]
    }
   ],
   "source": [
    "# Listar tablas en PostgreSQL\n",
    "print(\"=\" * 50)\n",
    "print(\"TABLAS EN POSTGRESQL (ETL_PRO)\")\n",
    "print(\"=\" * 50)\n",
    "inspector_pg = inspect(engine_postgres)\n",
    "tables_pg = inspector_pg.get_table_names()\n",
    "for i, table in enumerate(tables_pg, 1):\n",
    "    print(f\"{i}. {table}\")\n",
    "\n",
    "print(f\"\\nTotal: {len(tables_pg)} tablas\")\n",
    "\n",
    "# Listar tablas en SQL Server\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"TABLAS EN SQL SERVER (AdventureWorksDW2022)\")\n",
    "print(\"=\" * 50)\n",
    "try:\n",
    "    inspector_ss = inspect(engine_sqlserver)\n",
    "    tables_ss = inspector_ss.get_table_names()\n",
    "    for i, table in enumerate(tables_ss, 1):\n",
    "        print(f\"{i}. {table}\")\n",
    "    print(f\"\\nTotal: {len(tables_ss)} tablas\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al listar tablas de SQL Server: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8787a477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL (dim_product): 606\n",
      "Registros en SQL Server (DimProduct): 606\n",
      "\n",
      "================================================================================\n",
      "Mismo numero de registros: 606\n",
      "\n",
      "================================================================================\n",
      "COLUMNAS:\n",
      "\n",
      "PostgreSQL: ['productkey', 'productalternatekey', 'productsubcategorykey', 'weightunitmeasurecode', 'sizeunitmeasurecode', 'englishproductname', 'standardcost', 'finishedgoodsflag', 'color', 'safetystocklevel', 'reorderpoint', 'listprice', 'size', 'sizerange', 'weight', 'daystomanufacture', 'productline', 'dealerprice', 'class', 'style', 'modelname', 'largephoto', 'englishdescription', 'startdate', 'enddate', 'status']\n",
      "\n",
      "SQL Server: ['ProductKey', 'ProductAlternateKey', 'ProductSubcategoryKey', 'WeightUnitMeasureCode', 'SizeUnitMeasureCode', 'EnglishProductName', 'SpanishProductName', 'FrenchProductName', 'StandardCost', 'FinishedGoodsFlag', 'Color', 'SafetyStockLevel', 'ReorderPoint', 'ListPrice', 'Size', 'SizeRange', 'Weight', 'DaysToManufacture', 'ProductLine', 'DealerPrice', 'Class', 'Style', 'ModelName', 'LargePhoto', 'EnglishDescription', 'FrenchDescription', 'ChineseDescription', 'ArabicDescription', 'HebrewDescription', 'ThaiDescription', 'GermanDescription', 'JapaneseDescription', 'TurkishDescription', 'StartDate', 'EndDate', 'Status']\n",
      "\n",
      "================================================================================\n",
      "Columnas comunes para comparar: 26\n",
      "['class', 'color', 'daystomanufacture', 'dealerprice', 'enddate', 'englishdescription', 'englishproductname', 'finishedgoodsflag', 'largephoto', 'listprice', 'modelname', 'productalternatekey', 'productkey', 'productline', 'productsubcategorykey', 'reorderpoint', 'safetystocklevel', 'size', 'sizerange', 'sizeunitmeasurecode', 'standardcost', 'startdate', 'status', 'style', 'weight', 'weightunitmeasurecode']\n",
      "\n",
      "================================================================================\n",
      "COMPARACION DE DATOS:\n",
      "\n",
      "Diferencias en columna 'class': 488 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 2: PG='L ' vs SS='None'\n",
      "   - Fila 3: PG='M ' vs SS='None'\n",
      "   - Fila 4: PG='H ' vs SS='None'\n",
      "   - Fila 5: PG='None' vs SS='L '\n",
      "   - Fila 6: PG='None' vs SS='M '\n",
      "\n",
      "Diferencias en columna 'color': 564 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 0: PG='None' vs SS='NA'\n",
      "   - Fila 1: PG='None' vs SS='NA'\n",
      "   - Fila 2: PG='None' vs SS='NA'\n",
      "   - Fila 3: PG='None' vs SS='NA'\n",
      "   - Fila 4: PG='None' vs SS='NA'\n",
      "\n",
      "Diferencias en columna 'daystomanufacture': 434 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 3: PG='1' vs SS='0'\n",
      "   - Fila 7: PG='1' vs SS='0'\n",
      "   - Fila 9: PG='4' vs SS='0'\n",
      "   - Fila 10: PG='4' vs SS='0'\n",
      "   - Fila 11: PG='4' vs SS='0'\n",
      "\n",
      "Diferencias en columna 'dealerprice': 573 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 2: PG='32.394' vs SS='nan'\n",
      "   - Fila 4: PG='72.894' vs SS='nan'\n",
      "   - Fila 9: PG='323.994' vs SS='nan'\n",
      "   - Fila 10: PG='323.994' vs SS='nan'\n",
      "   - Fila 11: PG='323.994' vs SS='nan'\n",
      "\n",
      "Diferencias en columna 'enddate': 335 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 23: PG='2013-05-29 00:00:00+00:00' vs SS='NaT'\n",
      "   - Fila 24: PG='2013-05-29 00:00:00+00:00' vs SS='NaT'\n",
      "   - Fila 25: PG='2013-05-29 00:00:00+00:00' vs SS='NaT'\n",
      "   - Fila 26: PG='2013-05-29 00:00:00+00:00' vs SS='NaT'\n",
      "   - Fila 28: PG='2013-05-29 00:00:00+00:00' vs SS='NaT'\n",
      "\n",
      "Diferencias en columna 'englishdescription': 606 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 0: PG='' vs SS='None'\n",
      "   - Fila 1: PG='' vs SS='None'\n",
      "   - Fila 2: PG='Chromoly steel.' vs SS='None'\n",
      "   - Fila 3: PG='Aluminum alloy cups; large diameter spindle.' vs SS='None'\n",
      "   - Fila 4: PG='Aluminum alloy cups and a hollow axle.' vs SS='None'\n",
      "\n",
      "Diferencias en columna 'englishproductname': 604 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 2: PG='LL Bottom Bracket' vs SS='BB Ball Bearing'\n",
      "   - Fila 3: PG='ML Bottom Bracket' vs SS='Headset Ball Bearings'\n",
      "   - Fila 4: PG='HL Bottom Bracket' vs SS='Blade'\n",
      "   - Fila 5: PG='Mountain Bottle Cage' vs SS='LL Crankarm'\n",
      "   - Fila 6: PG='Road Bottle Cage' vs SS='ML Crankarm'\n",
      "\n",
      "Diferencias en columna 'finishedgoodsflag': 370 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 2: PG='True' vs SS='False'\n",
      "   - Fila 3: PG='True' vs SS='False'\n",
      "   - Fila 4: PG='True' vs SS='False'\n",
      "   - Fila 5: PG='True' vs SS='False'\n",
      "   - Fila 6: PG='True' vs SS='False'\n",
      "\n",
      "Diferencias en columna 'largephoto': 606 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 0: PG='\\x474946383961f0009500f700000000008000000080008080' vs SS='b'GIF89a\\xf0\\x00\\x95\\x00\\xf7\\x00\\x00\\x00\\x00\\x00\\x'\n",
      "   - Fila 1: PG='\\x474946383961f0009500f700000000008000000080008080' vs SS='b'GIF89a\\xf0\\x00\\x95\\x00\\xf7\\x00\\x00\\x00\\x00\\x00\\x'\n",
      "   - Fila 2: PG='\\x474946383961f0009500f700000000008000000080008080' vs SS='b'GIF89a\\xf0\\x00\\x95\\x00\\xf7\\x00\\x00\\x00\\x00\\x00\\x'\n",
      "   - Fila 3: PG='\\x474946383961f0009500f700000000008000000080008080' vs SS='b'GIF89a\\xf0\\x00\\x95\\x00\\xf7\\x00\\x00\\x00\\x00\\x00\\x'\n",
      "   - Fila 4: PG='\\x474946383961f0009500f700000000008000000080008080' vs SS='b'GIF89a\\xf0\\x00\\x95\\x00\\xf7\\x00\\x00\\x00\\x00\\x00\\x'\n",
      "\n",
      "Diferencias en columna 'listprice': 582 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 2: PG='53.99' vs SS='nan'\n",
      "   - Fila 3: PG='101.24' vs SS='nan'\n",
      "   - Fila 4: PG='121.49' vs SS='nan'\n",
      "   - Fila 5: PG='9.99' vs SS='nan'\n",
      "   - Fila 6: PG='8.99' vs SS='nan'\n",
      "\n",
      "Diferencias en columna 'modelname': 582 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 2: PG='LL Bottom Bracket' vs SS='None'\n",
      "   - Fila 3: PG='ML Bottom Bracket' vs SS='None'\n",
      "   - Fila 4: PG='HL Bottom Bracket' vs SS='None'\n",
      "   - Fila 5: PG='Mountain Bottle Cage' vs SS='None'\n",
      "   - Fila 6: PG='Road Bottle Cage' vs SS='None'\n",
      "\n",
      "Diferencias en columna 'productalternatekey': 604 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 2: PG='BB-7421' vs SS='BE-2349'\n",
      "   - Fila 3: PG='BB-8107' vs SS='BE-2908'\n",
      "   - Fila 4: PG='BB-9108' vs SS='BL-2036'\n",
      "   - Fila 5: PG='BC-M005' vs SS='CA-5965'\n",
      "   - Fila 6: PG='BC-R205' vs SS='CA-6738'\n",
      "\n",
      "Diferencias en columna 'productline': 493 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 5: PG='M ' vs SS='None'\n",
      "   - Fila 6: PG='R ' vs SS='None'\n",
      "   - Fila 9: PG='M ' vs SS='None'\n",
      "   - Fila 10: PG='M ' vs SS='None'\n",
      "   - Fila 11: PG='M ' vs SS='None'\n",
      "\n",
      "Diferencias en columna 'productsubcategorykey': 539 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 2: PG='5.0' vs SS='nan'\n",
      "   - Fila 3: PG='5.0' vs SS='nan'\n",
      "   - Fila 4: PG='5.0' vs SS='nan'\n",
      "   - Fila 5: PG='28.0' vs SS='nan'\n",
      "   - Fila 6: PG='28.0' vs SS='nan'\n",
      "\n",
      "Diferencias en columna 'reorderpoint': 470 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 2: PG='375' vs SS='600'\n",
      "   - Fila 3: PG='375' vs SS='600'\n",
      "   - Fila 4: PG='375' vs SS='600'\n",
      "   - Fila 5: PG='3' vs SS='375'\n",
      "   - Fila 6: PG='3' vs SS='375'\n",
      "\n",
      "Diferencias en columna 'safetystocklevel': 470 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 2: PG='500' vs SS='800'\n",
      "   - Fila 3: PG='500' vs SS='800'\n",
      "   - Fila 4: PG='500' vs SS='800'\n",
      "   - Fila 5: PG='4' vs SS='500'\n",
      "   - Fila 6: PG='4' vs SS='500'\n",
      "\n",
      "Diferencias en columna 'size': 482 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 9: PG='40' vs SS='None'\n",
      "   - Fila 10: PG='42' vs SS='None'\n",
      "   - Fila 11: PG='44' vs SS='None'\n",
      "   - Fila 12: PG='48' vs SS='None'\n",
      "   - Fila 13: PG='52' vs SS='None'\n",
      "\n",
      "Diferencias en columna 'sizerange': 487 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 9: PG='40-42 CM' vs SS='NA'\n",
      "   - Fila 10: PG='42-44 CM' vs SS='NA'\n",
      "   - Fila 11: PG='44-46 CM' vs SS='NA'\n",
      "   - Fila 12: PG='48-50 CM' vs SS='NA'\n",
      "   - Fila 13: PG='52-54 CM' vs SS='NA'\n",
      "\n",
      "Diferencias en columna 'sizeunitmeasurecode': 384 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 9: PG='CM ' vs SS='None'\n",
      "   - Fila 10: PG='CM ' vs SS='None'\n",
      "   - Fila 11: PG='CM ' vs SS='None'\n",
      "   - Fila 12: PG='CM ' vs SS='None'\n",
      "   - Fila 13: PG='CM ' vs SS='None'\n",
      "\n",
      "Diferencias en columna 'standardcost': 606 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 0: PG='0.0' vs SS='nan'\n",
      "   - Fila 1: PG='0.0' vs SS='nan'\n",
      "   - Fila 2: PG='23.9716' vs SS='nan'\n",
      "   - Fila 3: PG='44.9506' vs SS='nan'\n",
      "   - Fila 4: PG='53.9416' vs SS='nan'\n",
      "\n",
      "Diferencias en columna 'startdate': 606 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 0: PG='NaT' vs SS='2003-07-01 00:00:00'\n",
      "   - Fila 1: PG='NaT' vs SS='2003-07-01 00:00:00'\n",
      "   - Fila 2: PG='2013-05-30 00:00:00+00:00' vs SS='2003-07-01 00:00:00'\n",
      "   - Fila 3: PG='2013-05-30 00:00:00+00:00' vs SS='2003-07-01 00:00:00'\n",
      "   - Fila 4: PG='2013-05-30 00:00:00+00:00' vs SS='2003-07-01 00:00:00'\n",
      "\n",
      "Diferencias en columna 'status': 270 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 23: PG='None' vs SS='Current'\n",
      "   - Fila 24: PG='None' vs SS='Current'\n",
      "   - Fila 25: PG='None' vs SS='Current'\n",
      "   - Fila 26: PG='None' vs SS='Current'\n",
      "   - Fila 28: PG='None' vs SS='Current'\n",
      "\n",
      "Diferencias en columna 'style': 399 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 9: PG='U ' vs SS='None'\n",
      "   - Fila 10: PG='U ' vs SS='None'\n",
      "   - Fila 11: PG='U ' vs SS='None'\n",
      "   - Fila 12: PG='U ' vs SS='None'\n",
      "   - Fila 13: PG='U ' vs SS='None'\n",
      "\n",
      "Diferencias en columna 'weight': 481 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 2: PG='223.0' vs SS='nan'\n",
      "   - Fila 3: PG='168.0' vs SS='nan'\n",
      "   - Fila 4: PG='170.0' vs SS='nan'\n",
      "   - Fila 9: PG='27.35' vs SS='nan'\n",
      "   - Fila 10: PG='27.77' vs SS='nan'\n",
      "\n",
      "Diferencias en columna 'weightunitmeasurecode': 420 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 2: PG='G  ' vs SS='None'\n",
      "   - Fila 3: PG='G  ' vs SS='None'\n",
      "   - Fila 4: PG='G  ' vs SS='None'\n",
      "   - Fila 9: PG='LB ' vs SS='None'\n",
      "   - Fila 10: PG='LB ' vs SS='None'\n",
      "\n",
      "================================================================================\n",
      "Se encontraron diferencias entre las tablas.\n",
      "Total de filas con diferencias: 12455\n",
      "\n",
      "Ejemplos de diferencias encontradas (primeros 5):\n",
      " - Fila Index: 2, ProductKey: 3, Columna: class, PostgreSQL: 'L ' vs SQL Server: 'None'\n",
      " - Fila Index: 3, ProductKey: 4, Columna: class, PostgreSQL: 'M ' vs SQL Server: 'None'\n",
      " - Fila Index: 4, ProductKey: 5, Columna: class, PostgreSQL: 'H ' vs SQL Server: 'None'\n",
      " - Fila Index: 5, ProductKey: 6, Columna: class, PostgreSQL: 'None' vs SQL Server: 'L '\n",
      " - Fila Index: 6, ProductKey: 7, Columna: class, PostgreSQL: 'None' vs SQL Server: 'M '\n",
      "\n",
      "================================================================================\n",
      "\n",
      "MUESTRA DE DATOS (primeras 3 filas):\n",
      "\n",
      "PostgreSQL (dim_product):\n",
      "   productkey productalternatekey  productsubcategorykey  \\\n",
      "0           1             AR-5381                    NaN   \n",
      "1           2             BA-8327                    NaN   \n",
      "2           3             BB-7421                    5.0   \n",
      "\n",
      "  weightunitmeasurecode sizeunitmeasurecode englishproductname  standardcost  \\\n",
      "0                  None                None    Adjustable Race        0.0000   \n",
      "1                  None                None       Bearing Ball        0.0000   \n",
      "2                   G                  None  LL Bottom Bracket       23.9716   \n",
      "\n",
      "   finishedgoodsflag color  safetystocklevel  reorderpoint  listprice  size  \\\n",
      "0              False  None              1000           750        NaN  None   \n",
      "1              False  None              1000           750        NaN  None   \n",
      "2               True  None               500           375      53.99  None   \n",
      "\n",
      "  sizerange  weight  daystomanufacture productline  dealerprice class style  \\\n",
      "0        NA     NaN                  0        None          NaN  None  None   \n",
      "1        NA     NaN                  0        None          NaN  None  None   \n",
      "2        NA   223.0                  1        None       32.394    L   None   \n",
      "\n",
      "           modelname                                         largephoto  \\\n",
      "0               None  \\x474946383961f0009500f70000000000800000008000...   \n",
      "1               None  \\x474946383961f0009500f70000000000800000008000...   \n",
      "2  LL Bottom Bracket  \\x474946383961f0009500f70000000000800000008000...   \n",
      "\n",
      "  englishdescription                 startdate enddate   status  \n",
      "0                                          NaT     NaT  Current  \n",
      "1                                          NaT     NaT  Current  \n",
      "2    Chromoly steel. 2013-05-30 00:00:00+00:00     NaT  Current  \n",
      "\n",
      "SQL Server (DimProduct):\n",
      "   ProductKey ProductAlternateKey  ProductSubcategoryKey  \\\n",
      "0           1             AR-5381                    NaN   \n",
      "1           2             BA-8327                    NaN   \n",
      "2           3             BE-2349                    NaN   \n",
      "\n",
      "  WeightUnitMeasureCode SizeUnitMeasureCode EnglishProductName  \\\n",
      "0                  None                None    Adjustable Race   \n",
      "1                  None                None       Bearing Ball   \n",
      "2                  None                None    BB Ball Bearing   \n",
      "\n",
      "  SpanishProductName FrenchProductName  StandardCost  FinishedGoodsFlag Color  \\\n",
      "0                                                NaN              False    NA   \n",
      "1                                                NaN              False    NA   \n",
      "2                                                NaN              False    NA   \n",
      "\n",
      "   SafetyStockLevel  ReorderPoint  ListPrice  Size SizeRange  Weight  \\\n",
      "0              1000           750        NaN  None        NA     NaN   \n",
      "1              1000           750        NaN  None        NA     NaN   \n",
      "2               800           600        NaN  None        NA     NaN   \n",
      "\n",
      "   DaysToManufacture ProductLine  DealerPrice Class Style ModelName  \\\n",
      "0                  0        None          NaN  None  None      None   \n",
      "1                  0        None          NaN  None  None      None   \n",
      "2                  1        None          NaN  None  None      None   \n",
      "\n",
      "                                          LargePhoto EnglishDescription  \\\n",
      "0  b'GIF89a\\xf0\\x00\\x95\\x00\\xf7\\x00\\x00\\x00\\x00\\x...               None   \n",
      "1  b'GIF89a\\xf0\\x00\\x95\\x00\\xf7\\x00\\x00\\x00\\x00\\x...               None   \n",
      "2  b'GIF89a\\xf0\\x00\\x95\\x00\\xf7\\x00\\x00\\x00\\x00\\x...               None   \n",
      "\n",
      "  FrenchDescription ChineseDescription ArabicDescription HebrewDescription  \\\n",
      "0              None               None              None              None   \n",
      "1              None               None              None              None   \n",
      "2              None               None              None              None   \n",
      "\n",
      "  ThaiDescription GermanDescription JapaneseDescription TurkishDescription  \\\n",
      "0            None              None                None               None   \n",
      "1            None              None                None               None   \n",
      "2            None              None                None               None   \n",
      "\n",
      "   StartDate EndDate   Status  \n",
      "0 2003-07-01     NaT  Current  \n",
      "1 2003-07-01     NaT  Current  \n",
      "2 2003-07-01     NaT  Current  \n"
     ]
    }
   ],
   "source": [
    "# Verificar que los datos en dim_product (postgres) y DimProduct (sqlserver) sean iguales\n",
    "\n",
    "# Extraer datos de ambas bases de datos\n",
    "df_postgres_product = pd.read_sql(\"SELECT * FROM dim_product ORDER BY productkey\", engine_postgres)\n",
    "df_sqlserver_product = pd.read_sql(\"SELECT * FROM DimProduct ORDER BY ProductKey\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL (dim_product): {len(df_postgres_product)}\")\n",
    "print(f\"Registros en SQL Server (DimProduct): {len(df_sqlserver_product)}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Normalizar nombres de columnas para comparación (SQL Server usa PascalCase, Postgres usa snake_case)\n",
    "df_sqlserver_normalized = df_sqlserver_product.copy()\n",
    "df_sqlserver_normalized.columns = df_sqlserver_normalized.columns.str.lower()\n",
    "\n",
    "# Verificar si tienen el mismo número de registros\n",
    "if len(df_postgres_product) != len(df_sqlserver_normalized):\n",
    "    print(f\"ADVERTENCIA: Diferente numero de registros!\")\n",
    "    print(f\"   PostgreSQL: {len(df_postgres_product)} registros\")\n",
    "    print(f\"   SQL Server: {len(df_sqlserver_normalized)} registros\")\n",
    "else:\n",
    "    print(f\"Mismo numero de registros: {len(df_postgres_product)}\")\n",
    "\n",
    "# Verificar columnas\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"COLUMNAS:\")\n",
    "print(f\"\\nPostgreSQL: {list(df_postgres_product.columns)}\")\n",
    "print(f\"\\nSQL Server: {list(df_sqlserver_product.columns)}\")\n",
    "\n",
    "# Comparar columnas comunes\n",
    "common_cols = set(df_postgres_product.columns) & set(df_sqlserver_normalized.columns)\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Columnas comunes para comparar: {len(common_cols)}\")\n",
    "print(f\"{sorted(common_cols)}\")\n",
    "\n",
    "# Lista para almacenar las filas con diferencias\n",
    "rows_with_differences = []\n",
    "\n",
    "# Realizar comparación detallada si tienen las mismas columnas\n",
    "if len(common_cols) > 0:\n",
    "    # Ordenar por clave primaria y resetear índice\n",
    "    df_pg_sorted = df_postgres_product.sort_values('productkey').reset_index(drop=True)\n",
    "    df_ss_sorted = df_sqlserver_normalized.sort_values('productkey').reset_index(drop=True)\n",
    "    \n",
    "    # Seleccionar solo columnas comunes\n",
    "    df_pg_compare = df_pg_sorted[sorted(common_cols)]\n",
    "    df_ss_compare = df_ss_sorted[sorted(common_cols)]\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"COMPARACION DE DATOS:\")\n",
    "    \n",
    "    # Comparar valores\n",
    "    differences_found = False\n",
    "    for col in sorted(common_cols):\n",
    "        try:\n",
    "            # Convertir a string para comparación más robusta (maneja NaN, tipos diferentes, etc.)\n",
    "            # Usar errors='ignore' para manejar problemas de encoding\n",
    "            pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"\\nDiferencias en columna '{col}': {diff_count} registros diferentes\")\n",
    "                \n",
    "                # Guardar información de diferencias\n",
    "                diff_mask = pg_values != ss_values\n",
    "                if diff_mask.any():\n",
    "                    print(f\"   Ejemplos (primeros 5):\")\n",
    "                    diff_indices = diff_mask[diff_mask].index[:5]\n",
    "                    for idx in diff_indices:\n",
    "                        pg_val = str(df_pg_compare.loc[idx, col])[:50]\n",
    "                        ss_val = str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')[:50]\n",
    "                        print(f\"   - Fila {idx}: PG='{pg_val}' vs SS='{ss_val}'\")\n",
    "                    \n",
    "                    # Agregar todas las filas con diferencias en esta columna\n",
    "                    for idx in diff_mask[diff_mask].index:\n",
    "                        row_diff = {\n",
    "                            'fila_index': idx,\n",
    "                            'productkey': df_pg_compare.loc[idx, 'productkey'],\n",
    "                            'columna_diferente': col,\n",
    "                            'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                            'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                        }\n",
    "                        rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError al comparar columna '{col}': {str(e)}\")\n",
    "            print(f\"   Tipo en PostgreSQL: {df_pg_compare[col].dtype}\")\n",
    "            print(f\"   Tipo en SQL Server: {df_ss_compare[col].dtype}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"\\nLOS DATOS SON IDENTICOS! Todas las columnas comunes coinciden perfectamente.\")\n",
    "    else:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"Se encontraron diferencias entre las tablas.\")\n",
    "        print(f\"Total de filas con diferencias: {len(rows_with_differences)}\")\n",
    "        # Mostrar algunas diferencias encontradas\n",
    "        print(\"\\nEjemplos de diferencias encontradas (primeros 5):\")\n",
    "        for diff in rows_with_differences[:5]:\n",
    "            print(f\" - Fila Index: {diff['fila_index']}, ProductKey: {diff['productkey']}, Columna: {diff['columna_diferente']}, \"\n",
    "                  f\"PostgreSQL: '{diff['valor_postgres']}' vs SQL Server: '{diff['valor_sqlserver']}'\")\n",
    "else:\n",
    "    print(\"\\nNo se encontraron columnas comunes para comparar.\")\n",
    "\n",
    "# Mostrar muestra de datos\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"\\nMUESTRA DE DATOS (primeras 3 filas):\")\n",
    "print(\"\\nPostgreSQL (dim_product):\")\n",
    "print(df_postgres_product.head(3))\n",
    "print(\"\\nSQL Server (DimProduct):\")\n",
    "# Manejar posibles problemas de encoding en la visualización\n",
    "try:\n",
    "    print(df_sqlserver_product.head(3))\n",
    "except:\n",
    "    # Si hay problemas de encoding, mostrar con columnas específicas\n",
    "    print(\"(Nota: Algunos caracteres pueden no mostrarse correctamente debido a problemas de encoding)\")\n",
    "    for col in df_sqlserver_product.columns:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(df_sqlserver_product[col].head(3).apply(lambda x: str(x).encode('utf-8', errors='replace').decode('utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf77bc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 3652 | SQL Server: 3652\n",
      "Columnas comunes: 19\n",
      "LOS DATOS SON IDENTICOS!\n"
     ]
    }
   ],
   "source": [
    "# Comparar dim_date (postgres) vs DimDate (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM dim_date ORDER BY datekey\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM DimDate ORDER BY DateKey\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "if len(common_cols) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values('datekey').reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values('datekey').reset_index(drop=True)\n",
    "    \n",
    "    df_pg_compare = df_pg_sorted[sorted(common_cols)]\n",
    "    df_ss_compare = df_ss_sorted[sorted(common_cols)]\n",
    "    \n",
    "    differences_found = False\n",
    "    for col in sorted(common_cols):\n",
    "        try:\n",
    "            pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                \n",
    "                diff_mask = pg_values != ss_values\n",
    "                for idx in diff_mask[diff_mask].index:\n",
    "                    row_diff = {\n",
    "                        'tabla': 'dim_date',\n",
    "                        'fila_index': idx,\n",
    "                        'datekey': df_pg_compare.loc[idx, 'datekey'],\n",
    "                        'columna_diferente': col,\n",
    "                        'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                        'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                    }\n",
    "                    rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"Error en columna '{col}': {str(e)}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"LOS DATOS SON IDENTICOS!\")\n",
    "    else:\n",
    "        if rows_with_differences:\n",
    "            df_diff = pd.DataFrame(rows_with_differences)\n",
    "            csv_file = 'diferencias_dim_date.csv'\n",
    "            df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "            print(f\"Filas unicas con diferencias: {df_diff['fila_index'].nunique()}\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1bd82e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 11 | SQL Server: 11\n",
      "Columnas comunes: 5\n",
      "\n",
      "Comparando 11 claves comunes...\n",
      "LOS DATOS SON IDENTICOS en las claves comunes!\n"
     ]
    }
   ],
   "source": [
    "# Comparar dim_salesterritory (postgres) vs DimSalesTerritory (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM dim_salesterritory ORDER BY salesterritorykey\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM DimSalesTerritory ORDER BY SalesTerritoryKey\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "# Verificar si tienen diferente cantidad de registros\n",
    "if len(df_pg) != len(df_ss):\n",
    "    print(f\"\\nADVERTENCIA: Diferente cantidad de registros!\")\n",
    "    print(f\"Diferencia: {abs(len(df_pg) - len(df_ss))} registros\")\n",
    "    \n",
    "    # Encontrar claves que están en una tabla pero no en la otra\n",
    "    pg_keys = set(df_pg['salesterritorykey'])\n",
    "    ss_keys = set(df_ss['salesterritorykey'])\n",
    "    \n",
    "    only_pg = pg_keys - ss_keys\n",
    "    only_ss = ss_keys - pg_keys\n",
    "    \n",
    "    if only_pg:\n",
    "        print(f\"\\nClaves solo en PostgreSQL: {sorted(only_pg)}\")\n",
    "    if only_ss:\n",
    "        print(f\"Claves solo en SQL Server: {sorted(only_ss)}\")\n",
    "\n",
    "if len(common_cols) > 0 and len(df_pg) > 0 and len(df_ss) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values('salesterritorykey').reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values('salesterritorykey').reset_index(drop=True)\n",
    "    \n",
    "    # Comparar solo las claves que existen en ambas tablas\n",
    "    common_keys = set(df_pg_sorted['salesterritorykey']) & set(df_ss_sorted['salesterritorykey'])\n",
    "    \n",
    "    if len(common_keys) > 0:\n",
    "        df_pg_compare = df_pg_sorted[df_pg_sorted['salesterritorykey'].isin(common_keys)].reset_index(drop=True)\n",
    "        df_ss_compare = df_ss_sorted[df_ss_sorted['salesterritorykey'].isin(common_keys)].reset_index(drop=True)\n",
    "        \n",
    "        print(f\"\\nComparando {len(common_keys)} claves comunes...\")\n",
    "        \n",
    "        differences_found = False\n",
    "        for col in sorted(common_cols):\n",
    "            try:\n",
    "                pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "                ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "                \n",
    "                if not pg_values.equals(ss_values):\n",
    "                    differences_found = True\n",
    "                    diff_count = (pg_values != ss_values).sum()\n",
    "                    print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                    \n",
    "                    diff_mask = pg_values != ss_values\n",
    "                    for idx in diff_mask[diff_mask].index:\n",
    "                        row_diff = {\n",
    "                            'tabla': 'dim_salesterritory',\n",
    "                            'fila_index': idx,\n",
    "                            'salesterritorykey': df_pg_compare.loc[idx, 'salesterritorykey'],\n",
    "                            'columna_diferente': col,\n",
    "                            'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                            'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                        }\n",
    "                        rows_with_differences.append(row_diff)\n",
    "            except Exception as e:\n",
    "                print(f\"Error en columna '{col}': {str(e)}\")\n",
    "        \n",
    "        if not differences_found:\n",
    "            print(\"LOS DATOS SON IDENTICOS en las claves comunes!\")\n",
    "        else:\n",
    "            if rows_with_differences:\n",
    "                df_diff = pd.DataFrame(rows_with_differences)\n",
    "                csv_file = 'diferencias_dim_salesterritory.csv'\n",
    "                df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "                print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "                print(f\"Filas unicas con diferencias: {df_diff['fila_index'].nunique()}\")\n",
    "    else:\n",
    "        print(\"\\nNo hay claves comunes para comparar\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55048d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 10 | SQL Server: 10\n",
      "Columnas comunes: 3\n",
      "LOS DATOS SON IDENTICOS!\n"
     ]
    }
   ],
   "source": [
    "# Comparar dim_salesreason (postgres) vs DimSalesReason (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM dim_salesreason ORDER BY salesreasonkey\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM DimSalesReason ORDER BY SalesReasonKey\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "if len(common_cols) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values('salesreasonkey').reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values('salesreasonkey').reset_index(drop=True)\n",
    "    \n",
    "    df_pg_compare = df_pg_sorted[sorted(common_cols)]\n",
    "    df_ss_compare = df_ss_sorted[sorted(common_cols)]\n",
    "    \n",
    "    differences_found = False\n",
    "    for col in sorted(common_cols):\n",
    "        try:\n",
    "            pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                \n",
    "                diff_mask = pg_values != ss_values\n",
    "                for idx in diff_mask[diff_mask].index:\n",
    "                    row_diff = {\n",
    "                        'tabla': 'dim_salesreason',\n",
    "                        'fila_index': idx,\n",
    "                        'salesreasonkey': df_pg_compare.loc[idx, 'salesreasonkey'],\n",
    "                        'columna_diferente': col,\n",
    "                        'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                        'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                    }\n",
    "                    rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"Error en columna '{col}': {str(e)}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"LOS DATOS SON IDENTICOS!\")\n",
    "    else:\n",
    "        if rows_with_differences:\n",
    "            df_diff = pd.DataFrame(rows_with_differences)\n",
    "            csv_file = 'diferencias_dim_salesreason.csv'\n",
    "            df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "            print(f\"Filas unicas con diferencias: {df_diff['fila_index'].nunique()}\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a86d9a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 16 | SQL Server: 16\n",
      "Columnas comunes: 4\n",
      "Diferencias en 'enddate': 16 registros\n",
      "Diferencias en 'startdate': 16 registros\n",
      "\n",
      "Exportadas 32 diferencias a: diferencias_dim_promotion.csv\n",
      "Filas unicas con diferencias: 16\n"
     ]
    }
   ],
   "source": [
    "# Comparar dim_promotion (postgres) vs DimPromotion (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM dim_promotion ORDER BY promotionkey\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM DimPromotion ORDER BY PromotionKey\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "if len(common_cols) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values('promotionkey').reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values('promotionkey').reset_index(drop=True)\n",
    "    \n",
    "    df_pg_compare = df_pg_sorted[sorted(common_cols)]\n",
    "    df_ss_compare = df_ss_sorted[sorted(common_cols)]\n",
    "    \n",
    "    differences_found = False\n",
    "    for col in sorted(common_cols):\n",
    "        try:\n",
    "            pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                \n",
    "                diff_mask = pg_values != ss_values\n",
    "                for idx in diff_mask[diff_mask].index:\n",
    "                    row_diff = {\n",
    "                        'tabla': 'dim_promotion',\n",
    "                        'fila_index': idx,\n",
    "                        'promotionkey': df_pg_compare.loc[idx, 'promotionkey'],\n",
    "                        'columna_diferente': col,\n",
    "                        'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                        'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                    }\n",
    "                    rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"Error en columna '{col}': {str(e)}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"LOS DATOS SON IDENTICOS!\")\n",
    "    else:\n",
    "        if rows_with_differences:\n",
    "            df_diff = pd.DataFrame(rows_with_differences)\n",
    "            csv_file = 'diferencias_dim_promotion.csv'\n",
    "            df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "            print(f\"Filas unicas con diferencias: {df_diff['fila_index'].nunique()}\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36359126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 701 | SQL Server: 701\n",
      "Columnas comunes: 16\n",
      "Diferencias en 'addressline1': 26 registros\n",
      "Diferencias en 'annualrevenue': 701 registros\n",
      "Diferencias en 'annualsales': 701 registros\n",
      "Diferencias en 'businesstype': 470 registros\n",
      "Diferencias en 'geographykey': 22 registros\n",
      "Diferencias en 'minpaymentamount': 191 registros\n",
      "Diferencias en 'minpaymenttype': 569 registros\n",
      "Diferencias en 'phone': 38 registros\n",
      "Diferencias en 'resellername': 4 registros\n",
      "Diferencias en 'yearopened': 701 registros\n",
      "\n",
      "Exportadas 3423 diferencias a: diferencias_dim_reseller.csv\n",
      "Filas unicas con diferencias: 701\n"
     ]
    }
   ],
   "source": [
    "# Comparar dim_reseller (postgres) vs DimReseller (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM dim_reseller ORDER BY resellerkey\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM DimReseller ORDER BY ResellerKey\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "if len(common_cols) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values('resellerkey').reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values('resellerkey').reset_index(drop=True)\n",
    "    \n",
    "    df_pg_compare = df_pg_sorted[sorted(common_cols)]\n",
    "    df_ss_compare = df_ss_sorted[sorted(common_cols)]\n",
    "    \n",
    "    differences_found = False\n",
    "    for col in sorted(common_cols):\n",
    "        try:\n",
    "            pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                \n",
    "                diff_mask = pg_values != ss_values\n",
    "                for idx in diff_mask[diff_mask].index:\n",
    "                    row_diff = {\n",
    "                        'tabla': 'dim_reseller',\n",
    "                        'fila_index': idx,\n",
    "                        'resellerkey': df_pg_compare.loc[idx, 'resellerkey'],\n",
    "                        'columna_diferente': col,\n",
    "                        'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                        'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                    }\n",
    "                    rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"Error en columna '{col}': {str(e)}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"LOS DATOS SON IDENTICOS!\")\n",
    "    else:\n",
    "        if rows_with_differences:\n",
    "            df_diff = pd.DataFrame(rows_with_differences)\n",
    "            csv_file = 'diferencias_dim_reseller.csv'\n",
    "            df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "            print(f\"Filas unicas con diferencias: {df_diff['fila_index'].nunique()}\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84ced963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 64515 | SQL Server: 64515\n",
      "Columnas comunes: 3\n",
      "LOS DATOS SON IDENTICOS!\n"
     ]
    }
   ],
   "source": [
    "# Comparar fact_internet_sales_reason (postgres) vs FactInternetSalesReason (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM fact_internet_sales_reason ORDER BY salesordernumber, salesorderlinenumber, salesreasonid\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM FactInternetSalesReason ORDER BY SalesOrderNumber, SalesOrderLineNumber, SalesReasonKey\", engine_sqlserver)\n",
    "\n",
    "# Rename salesreasonid to salesreasonkey in PostgreSQL dataframe for consistency\n",
    "df_pg.rename(columns={'salesreasonid': 'salesreasonkey'}, inplace=True)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "if len(common_cols) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values(['salesordernumber', 'salesorderlinenumber', 'salesreasonkey']).reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values(['salesordernumber', 'salesorderlinenumber', 'salesreasonkey']).reset_index(drop=True)\n",
    "    \n",
    "    df_pg_compare = df_pg_sorted[sorted(common_cols)]\n",
    "    df_ss_compare = df_ss_sorted[sorted(common_cols)]\n",
    "    \n",
    "    differences_found = False\n",
    "    for col in sorted(common_cols):\n",
    "        try:\n",
    "            pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                \n",
    "                diff_mask = pg_values != ss_values\n",
    "                for idx in diff_mask[diff_mask].index[:100]:  # Limitar a 100 diferencias por columna\n",
    "                    row_diff = {\n",
    "                        'tabla': 'fact_internet_sales_reason',\n",
    "                        'fila_index': idx,\n",
    "                        'salesordernumber': df_pg_compare.loc[idx, 'salesordernumber'],\n",
    "                        'salesorderlinenumber': df_pg_compare.loc[idx, 'salesorderlinenumber'],\n",
    "                        'salesreasonkey': df_pg_compare.loc[idx, 'salesreasonkey'],\n",
    "                        'columna_diferente': col,\n",
    "                        'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                        'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                    }\n",
    "                    rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"Error en columna '{col}': {str(e)}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"LOS DATOS SON IDENTICOS!\")\n",
    "    else:\n",
    "        if rows_with_differences:\n",
    "            df_diff = pd.DataFrame(rows_with_differences)\n",
    "            csv_file = 'diferencias_fact_internet_sales_reason.csv'\n",
    "            df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "            print(f\"Filas unicas con diferencias: {df_diff['fila_index'].nunique()}\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b34f73b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 60398 | SQL Server: 60398\n",
      "Columnas comunes: 25\n",
      "Diferencias en 'currencykey': 60398 registros\n",
      "Diferencias en 'duedate': 60398 registros\n",
      "Diferencias en 'extendedamount': 1075 registros\n",
      "Diferencias en 'freight': 49452 registros\n",
      "Diferencias en 'orderdate': 60398 registros\n",
      "Diferencias en 'productkey': 60398 registros\n",
      "Diferencias en 'productstandardcost': 2449 registros\n",
      "Diferencias en 'salesamount': 1075 registros\n",
      "Diferencias en 'shipdate': 60398 registros\n",
      "Diferencias en 'taxamt': 25568 registros\n",
      "Diferencias en 'totalproductcost': 2449 registros\n",
      "Diferencias en 'unitprice': 1075 registros\n",
      "\n",
      "Exportadas 1200 diferencias a: diferencias_fact_internet_sales.csv\n",
      "Filas unicas con diferencias: 419\n"
     ]
    }
   ],
   "source": [
    "# Comparar fact_internet_sales (postgres) vs FactInternetSales (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM fact_internet_sales ORDER BY salesordernumber, salesorderlinenumber\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM FactInternetSales ORDER BY SalesOrderNumber, SalesOrderLineNumber\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "if len(common_cols) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values(['salesordernumber', 'salesorderlinenumber']).reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values(['salesordernumber', 'salesorderlinenumber']).reset_index(drop=True)\n",
    "    \n",
    "    df_pg_compare = df_pg_sorted[sorted(common_cols)]\n",
    "    df_ss_compare = df_ss_sorted[sorted(common_cols)]\n",
    "    \n",
    "    differences_found = False\n",
    "    for col in sorted(common_cols):\n",
    "        try:\n",
    "            pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                \n",
    "                diff_mask = pg_values != ss_values\n",
    "                for idx in diff_mask[diff_mask].index[:100]:  # Limitar a 100 diferencias por columna\n",
    "                    row_diff = {\n",
    "                        'tabla': 'fact_internet_sales',\n",
    "                        'fila_index': idx,\n",
    "                        'salesordernumber': df_pg_compare.loc[idx, 'salesordernumber'],\n",
    "                        'salesorderlinenumber': df_pg_compare.loc[idx, 'salesorderlinenumber'],\n",
    "                        'columna_diferente': col,\n",
    "                        'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                        'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                    }\n",
    "                    rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"Error en columna '{col}': {str(e)}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"LOS DATOS SON IDENTICOS!\")\n",
    "    else:\n",
    "        if rows_with_differences:\n",
    "            df_diff = pd.DataFrame(rows_with_differences)\n",
    "            csv_file = 'diferencias_fact_internet_sales.csv'\n",
    "            df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "            print(f\"Filas unicas con diferencias: {df_diff['fila_index'].nunique()}\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6796a9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 655 | SQL Server: 655\n",
      "Columnas comunes: 8\n",
      "Diferencias en 'city': 10 registros\n",
      "Diferencias en 'postalcode': 25 registros\n",
      "Diferencias en 'stateprovincecode': 565 registros\n",
      "\n",
      "Exportadas 600 diferencias a: diferencias_dim_geography.csv\n",
      "Filas unicas con diferencias: 590\n"
     ]
    }
   ],
   "source": [
    "# Comparar dim_geography (postgres) vs DimGeography (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM dim_geography ORDER BY geographykey\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM DimGeography ORDER BY GeographyKey\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "if len(common_cols) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values('geographykey').reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values('geographykey').reset_index(drop=True)\n",
    "    \n",
    "    df_pg_compare = df_pg_sorted[sorted(common_cols)]\n",
    "    df_ss_compare = df_ss_sorted[sorted(common_cols)]\n",
    "    \n",
    "    differences_found = False\n",
    "    for col in sorted(common_cols):\n",
    "        try:\n",
    "            pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                \n",
    "                diff_mask = pg_values != ss_values\n",
    "                for idx in diff_mask[diff_mask].index:\n",
    "                    row_diff = {\n",
    "                        'tabla': 'dim_geography',\n",
    "                        'fila_index': idx,\n",
    "                        'geographykey': df_pg_compare.loc[idx, 'geographykey'],\n",
    "                        'columna_diferente': col,\n",
    "                        'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                        'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                    }\n",
    "                    rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"Error en columna '{col}': {str(e)}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"LOS DATOS SON IDENTICOS!\")\n",
    "    else:\n",
    "        if rows_with_differences:\n",
    "            df_diff = pd.DataFrame(rows_with_differences)\n",
    "            csv_file = 'diferencias_dim_geography.csv'\n",
    "            df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "            print(f\"Filas unicas con diferencias: {df_diff['fila_index'].nunique()}\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33231f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 18484 | SQL Server: 18484\n",
      "Columnas comunes: 21\n",
      "Diferencias en 'addressline1': 2 registros\n",
      "Diferencias en 'birthdate': 18484 registros\n",
      "Diferencias en 'datefirstpurchase': 18484 registros\n",
      "Diferencias en 'geographykey': 850 registros\n",
      "Diferencias en 'yearlyincome': 18484 registros\n",
      "\n",
      "Exportadas 56304 diferencias a: diferencias_dim_customer.csv\n",
      "Filas unicas con diferencias: 18484\n"
     ]
    }
   ],
   "source": [
    "# Comparar dim_customer (postgres) vs DimCustomer (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM dim_customer ORDER BY customerkey\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM DimCustomer ORDER BY CustomerKey\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "if len(common_cols) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values('customerkey').reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values('customerkey').reset_index(drop=True)\n",
    "    \n",
    "    df_pg_compare = df_pg_sorted[sorted(common_cols)]\n",
    "    df_ss_compare = df_ss_sorted[sorted(common_cols)]\n",
    "    \n",
    "    differences_found = False\n",
    "    for col in sorted(common_cols):\n",
    "        try:\n",
    "            pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                \n",
    "                diff_mask = pg_values != ss_values\n",
    "                for idx in diff_mask[diff_mask].index:\n",
    "                    row_diff = {\n",
    "                        'tabla': 'dim_customer',\n",
    "                        'fila_index': idx,\n",
    "                        'customerkey': df_pg_compare.loc[idx, 'customerkey'],\n",
    "                        'columna_diferente': col,\n",
    "                        'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                        'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                    }\n",
    "                    rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"Error en columna '{col}': {str(e)}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"LOS DATOS SON IDENTICOS!\")\n",
    "    else:\n",
    "        if rows_with_differences:\n",
    "            df_diff = pd.DataFrame(rows_with_differences)\n",
    "            csv_file = 'diferencias_dim_customer.csv'\n",
    "            df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "            print(f\"Filas unicas con diferencias: {df_diff['fila_index'].nunique()}\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e984182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 105 | SQL Server: 105\n",
      "Columnas comunes: 3\n",
      "Diferencias en 'currencyalternatekey': 102 registros\n",
      "Diferencias en 'currencyname': 102 registros\n",
      "\n",
      "Exportadas 204 diferencias a: diferencias_dim_currency.csv\n",
      "Filas unicas con diferencias: 102\n"
     ]
    }
   ],
   "source": [
    "# Comparar dim_currency (postgres) vs DimCurrency (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM dim_currency ORDER BY currencykey\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM DimCurrency ORDER BY CurrencyKey\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "if len(common_cols) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values('currencykey').reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values('currencykey').reset_index(drop=True)\n",
    "    \n",
    "    df_pg_compare = df_pg_sorted[sorted(common_cols)]\n",
    "    df_ss_compare = df_ss_sorted[sorted(common_cols)]\n",
    "    \n",
    "    differences_found = False\n",
    "    for col in sorted(common_cols):\n",
    "        try:\n",
    "            pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                \n",
    "                diff_mask = pg_values != ss_values\n",
    "                for idx in diff_mask[diff_mask].index:\n",
    "                    row_diff = {\n",
    "                        'tabla': 'dim_currency',\n",
    "                        'fila_index': idx,\n",
    "                        'currencykey': df_pg_compare.loc[idx, 'currencykey'],\n",
    "                        'columna_diferente': col,\n",
    "                        'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                        'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                    }\n",
    "                    rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"Error en columna '{col}': {str(e)}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"LOS DATOS SON IDENTICOS!\")\n",
    "    else:\n",
    "        if rows_with_differences:\n",
    "            df_diff = pd.DataFrame(rows_with_differences)\n",
    "            csv_file = 'diferencias_dim_currency.csv'\n",
    "            df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "            print(f\"Filas unicas con diferencias: {df_diff['fila_index'].nunique()}\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04c5b031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 60855 | SQL Server: 60855\n",
      "Columnas comunes: 27\n",
      "\n",
      "📊 Comparando 60855 registros comunes...\n",
      "Diferencias en 'currencykey': 60855 registros\n",
      "Diferencias en 'discountamount': 2818 registros\n",
      "Diferencias en 'duedate': 60855 registros\n",
      "Diferencias en 'duedatekey': 60855 registros\n",
      "Diferencias en 'employeekey': 3189 registros\n",
      "Diferencias en 'extendedamount': 5517 registros\n",
      "Diferencias en 'freight': 60840 registros\n",
      "Diferencias en 'orderdate': 60855 registros\n",
      "Diferencias en 'orderdatekey': 60855 registros\n",
      "Diferencias en 'productkey': 60855 registros\n",
      "Diferencias en 'productstandardcost': 14323 registros\n",
      "Diferencias en 'salesamount': 7664 registros\n",
      "Diferencias en 'shipdate': 60855 registros\n",
      "Diferencias en 'shipdatekey': 60855 registros\n",
      "Diferencias en 'taxamt': 60840 registros\n",
      "Diferencias en 'totalproductcost': 19895 registros\n",
      "Diferencias en 'unitprice': 18 registros\n",
      "\n",
      "⚠️  Se encontraron diferencias en los valores\n",
      "\n",
      "📝 Exportadas 1618 diferencias a: diferencias_fact_reseller_sales.csv\n",
      "   - Diferencias en valores: 1618\n"
     ]
    }
   ],
   "source": [
    "# Comparar fact_reseller_sales (postgres) vs FactResellerSales (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM fact_reseller_sales ORDER BY salesordernumber, salesorderlinenumber\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM FactResellerSales ORDER BY SalesOrderNumber, SalesOrderLineNumber\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "# Verificar diferencia en cantidad de registros\n",
    "diff_count = abs(len(df_pg) - len(df_ss))\n",
    "if diff_count > 0:\n",
    "    print(f\"\\n⚠️  ADVERTENCIA: Hay {diff_count} registros de diferencia en el conteo total\")\n",
    "    \n",
    "    # Identificar registros únicos en cada base de datos\n",
    "    pg_keys = set(df_pg.apply(lambda x: f\"{x['salesordernumber']}-{x['salesorderlinenumber']}\", axis=1))\n",
    "    ss_keys = set(df_ss.apply(lambda x: f\"{x['salesordernumber']}-{x['salesorderlinenumber']}\", axis=1))\n",
    "    \n",
    "    only_pg = pg_keys - ss_keys\n",
    "    only_ss = ss_keys - pg_keys\n",
    "    \n",
    "    if only_pg:\n",
    "        print(f\"   Registros SOLO en PostgreSQL: {len(only_pg)}\")\n",
    "        for key in list(only_pg)[:5]:  # Mostrar solo los primeros 5\n",
    "            rows_with_differences.append({\n",
    "                'tabla': 'fact_reseller_sales',\n",
    "                'salesordernumber': key.split('-')[0],\n",
    "                'salesorderlinenumber': key.split('-')[1],\n",
    "                'columna_diferente': 'REGISTRO_COMPLETO',\n",
    "                'valor_postgres': 'EXISTE',\n",
    "                'valor_sqlserver': 'NO_EXISTE'\n",
    "            })\n",
    "    \n",
    "    if only_ss:\n",
    "        print(f\"   Registros SOLO en SQL Server: {len(only_ss)}\")\n",
    "        for key in list(only_ss)[:5]:  # Mostrar solo los primeros 5\n",
    "            rows_with_differences.append({\n",
    "                'tabla': 'fact_reseller_sales',\n",
    "                'salesordernumber': key.split('-')[0],\n",
    "                'salesorderlinenumber': key.split('-')[1],\n",
    "                'columna_diferente': 'REGISTRO_COMPLETO',\n",
    "                'valor_postgres': 'NO_EXISTE',\n",
    "                'valor_sqlserver': 'EXISTE'\n",
    "            })\n",
    "\n",
    "# Comparar solo los registros que existen en ambas bases de datos\n",
    "if len(common_cols) > 0:\n",
    "    # Crear una clave compuesta para hacer merge\n",
    "    df_pg['_merge_key'] = df_pg['salesordernumber'] + '-' + df_pg['salesorderlinenumber'].astype(str)\n",
    "    df_ss['_merge_key'] = df_ss['salesordernumber'] + '-' + df_ss['salesorderlinenumber'].astype(str)\n",
    "    \n",
    "    # Hacer merge inner para comparar solo registros comunes\n",
    "    merged = df_pg.merge(\n",
    "        df_ss,\n",
    "        on='_merge_key',\n",
    "        how='inner',\n",
    "        suffixes=('_pg', '_ss')\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n📊 Comparando {len(merged)} registros comunes...\")\n",
    "    \n",
    "    differences_found = False\n",
    "    cols_to_compare = [col for col in common_cols if col not in ['salesordernumber', 'salesorderlinenumber']]\n",
    "    \n",
    "    for col in sorted(cols_to_compare):\n",
    "        try:\n",
    "            pg_col = f\"{col}_pg\" if f\"{col}_pg\" in merged.columns else col\n",
    "            ss_col = f\"{col}_ss\" if f\"{col}_ss\" in merged.columns else col\n",
    "            \n",
    "            if pg_col not in merged.columns or ss_col not in merged.columns:\n",
    "                continue\n",
    "            \n",
    "            pg_values = merged[pg_col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = merged[ss_col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                \n",
    "                diff_mask = pg_values != ss_values\n",
    "                for idx in diff_mask[diff_mask].index[:100]:  # Limitar a 100 diferencias por columna\n",
    "                    row_diff = {\n",
    "                        'tabla': 'fact_reseller_sales',\n",
    "                        'salesordernumber': merged.loc[idx, 'salesordernumber_pg'] if 'salesordernumber_pg' in merged.columns else merged.loc[idx, 'salesordernumber'],\n",
    "                        'salesorderlinenumber': merged.loc[idx, 'salesorderlinenumber_pg'] if 'salesorderlinenumber_pg' in merged.columns else merged.loc[idx, 'salesorderlinenumber'],\n",
    "                        'columna_diferente': col,\n",
    "                        'valor_postgres': str(merged.loc[idx, pg_col]).encode('utf-8', errors='ignore').decode('utf-8')[:100],\n",
    "                        'valor_sqlserver': str(merged.loc[idx, ss_col]).encode('utf-8', errors='ignore').decode('utf-8')[:100]\n",
    "                    }\n",
    "                    rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"Error en columna '{col}': {str(e)}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"\\n✅ LOS DATOS SON IDENTICOS en los registros comunes!\")\n",
    "    else:\n",
    "        print(f\"\\n⚠️  Se encontraron diferencias en los valores\")\n",
    "    \n",
    "    # Exportar diferencias a CSV\n",
    "    if rows_with_differences:\n",
    "        df_diff = pd.DataFrame(rows_with_differences)\n",
    "        csv_file = 'diferencias_fact_reseller_sales.csv'\n",
    "        df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\n📝 Exportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "        \n",
    "        # Contar tipos de diferencias\n",
    "        value_diffs = len(df_diff[df_diff['columna_diferente'] != 'REGISTRO_COMPLETO'])\n",
    "        record_diffs = len(df_diff[df_diff['columna_diferente'] == 'REGISTRO_COMPLETO'])\n",
    "        \n",
    "        if value_diffs > 0:\n",
    "            print(f\"   - Diferencias en valores: {value_diffs}\")\n",
    "        if record_diffs > 0:\n",
    "            print(f\"   - Registros únicos: {record_diffs}\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
