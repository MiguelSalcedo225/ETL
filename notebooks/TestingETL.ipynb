{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "511949af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio de trabajo: /home/paelsam/Documents/Ciencia de Datos/ETL/notebooks\n"
     ]
    }
   ],
   "source": [
    "# Establecer directorio de trabajo para guardar archivos CSV\n",
    "import os\n",
    "os.chdir('/home/paelsam/Documents/Ciencia de Datos/ETL/notebooks')\n",
    "print(f\"Directorio de trabajo: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6af647b",
   "metadata": {},
   "source": [
    "## 1. Importar librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "b3259e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "from sqlalchemy import create_engine, text, inspect\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44cf277",
   "metadata": {},
   "source": [
    "## 2. Cargar configuración desde config.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "90b367f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuración PostgreSQL: {'drivername': 'postgresql', 'dbname': 'prueba', 'user': 'postgres', 'password': 'postgres', 'host': 'localhost', 'port': 5432}\n",
      "\n",
      "Configuración SQL Server: {'drivername': 'mssql+pyodbc', 'dbname': 'AdventureWorksDW2022', 'user': 'sa', 'password': 'r00t.R00T', 'host': 'localhost', 'port': 1433, 'driver': 'FreeTDS'}\n"
     ]
    }
   ],
   "source": [
    "# Cargar configuración\n",
    "with open('../config.yml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Obtener configuraciones específicas\n",
    "config_postgres = config['ETL_PRO']\n",
    "config_sqlserver = config['SQL_SERVER_DW']\n",
    "\n",
    "print(\"Configuración PostgreSQL:\", config_postgres)\n",
    "print(\"\\nConfiguración SQL Server:\", config_sqlserver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245e89c9",
   "metadata": {},
   "source": [
    "## 3. Conexión a PostgreSQL (ETL_PRO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "35715129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectado exitosamente a PostgreSQL\n",
      "Versión: PostgreSQL 17.6 (Debian 17.6-2.pgdg13+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 14.2.0-19) 14.2.0, 64-bit\n"
     ]
    }
   ],
   "source": [
    "# Construir URL de conexión para PostgreSQL\n",
    "url_postgres = (\n",
    "    f\"{config_postgres['drivername']}://\"\n",
    "    f\"{config_postgres['user']}:{config_postgres['password']}@\"\n",
    "    f\"{config_postgres['host']}:{config_postgres['port']}/\"\n",
    "    f\"{config_postgres['dbname']}\"\n",
    ")\n",
    "\n",
    "# Crear engine de SQLAlchemy para PostgreSQL\n",
    "engine_postgres = create_engine(url_postgres)\n",
    "\n",
    "# Verificar conexión\n",
    "try:\n",
    "    with engine_postgres.connect() as conn:\n",
    "        result = conn.execute(text(\"SELECT version();\"))\n",
    "        version = result.fetchone()\n",
    "        print(\"Conectado exitosamente a PostgreSQL\")\n",
    "        print(f\"Versión: {version[0]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al conectar a PostgreSQL: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90e3c4d",
   "metadata": {},
   "source": [
    "## 4. Conexión a SQL Server (AdventureWorksDW2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "9133f82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectado exitosamente a SQL Server\n",
      "Versión: Microsoft SQL Server 2022 (RTM-CU21) (KB5065865) - 16.0.4215.2 (X64) \n",
      "\tAug 11 2025 13:24:21 \n",
      "\tCopyri...\n"
     ]
    }
   ],
   "source": [
    "# Construir URL de conexión para SQL Server\n",
    "# Nota: Asegúrate de tener instalado pyodbc y el driver ODBC para SQL Server\n",
    "url_sqlserver = (\n",
    "    f\"{config_sqlserver['drivername']}://\"\n",
    "    f\"{config_sqlserver['user']}:{config_sqlserver['password']}@\"\n",
    "    f\"{config_sqlserver['host']}:{config_sqlserver['port']}/\"\n",
    "    f\"{config_sqlserver['dbname']}\"\n",
    "    f\"?driver={config_sqlserver['driver'].replace(' ', '+')}\"\n",
    ")\n",
    "\n",
    "# Crear engine de SQLAlchemy para SQL Server\n",
    "engine_sqlserver = create_engine(url_sqlserver)\n",
    "\n",
    "# Verificar conexión\n",
    "try:\n",
    "    with engine_sqlserver.connect() as conn:\n",
    "        result = conn.execute(text(\"SELECT @@VERSION;\"))\n",
    "        version = result.fetchone()\n",
    "        print(\"Conectado exitosamente a SQL Server\")\n",
    "        print(f\"Versión: {version[0][:100]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al conectar a SQL Server: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6c2689",
   "metadata": {},
   "source": [
    "## 5. Ejemplo: Listar tablas en ambas bases de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "f21045c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "TABLAS EN POSTGRESQL (ETL_PRO)\n",
      "==================================================\n",
      "1. dim_salesreason\n",
      "2. dim_geography\n",
      "3. fact_internet_sales_reason\n",
      "4. dim_product\n",
      "5. fact_internet_sales\n",
      "6. dim_customer\n",
      "7. dim_promotion\n",
      "8. dim_currency\n",
      "9. dim_salesterritory\n",
      "10. dim_date\n",
      "11. fact_reseller_sales\n",
      "12. dim_reseller\n",
      "13. dim_employee\n",
      "\n",
      "Total: 13 tablas\n",
      "\n",
      "==================================================\n",
      "TABLAS EN SQL SERVER (AdventureWorksDW2022)\n",
      "==================================================\n",
      "1. AdventureWorksDWBuildVersion\n",
      "2. DatabaseLog\n",
      "3. DimAccount\n",
      "4. DimCurrency\n",
      "5. DimCustomer\n",
      "6. DimDate\n",
      "7. DimDepartmentGroup\n",
      "8. DimEmployee\n",
      "9. DimGeography\n",
      "10. DimOrganization\n",
      "11. DimProduct\n",
      "12. DimProductCategory\n",
      "13. DimProductSubcategory\n",
      "14. DimPromotion\n",
      "15. DimReseller\n",
      "16. DimSalesReason\n",
      "17. DimSalesTerritory\n",
      "18. DimScenario\n",
      "19. FactAdditionalInternationalProductDescription\n",
      "20. FactCallCenter\n",
      "21. FactCurrencyRate\n",
      "22. FactFinance\n",
      "23. FactInternetSales\n",
      "24. FactInternetSalesReason\n",
      "25. FactProductInventory\n",
      "26. FactResellerSales\n",
      "27. FactSalesQuota\n",
      "28. FactSurveyResponse\n",
      "29. NewFactCurrencyRate\n",
      "30. ProspectiveBuyer\n",
      "31. sysdiagrams\n",
      "\n",
      "Total: 31 tablas\n"
     ]
    }
   ],
   "source": [
    "# Listar tablas en PostgreSQL\n",
    "print(\"=\" * 50)\n",
    "print(\"TABLAS EN POSTGRESQL (ETL_PRO)\")\n",
    "print(\"=\" * 50)\n",
    "inspector_pg = inspect(engine_postgres)\n",
    "tables_pg = inspector_pg.get_table_names()\n",
    "for i, table in enumerate(tables_pg, 1):\n",
    "    print(f\"{i}. {table}\")\n",
    "\n",
    "print(f\"\\nTotal: {len(tables_pg)} tablas\")\n",
    "\n",
    "# Listar tablas en SQL Server\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"TABLAS EN SQL SERVER (AdventureWorksDW2022)\")\n",
    "print(\"=\" * 50)\n",
    "try:\n",
    "    inspector_ss = inspect(engine_sqlserver)\n",
    "    tables_ss = inspector_ss.get_table_names()\n",
    "    for i, table in enumerate(tables_ss, 1):\n",
    "        print(f\"{i}. {table}\")\n",
    "    print(f\"\\nTotal: {len(tables_ss)} tablas\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al listar tablas de SQL Server: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "8787a477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL (dim_product): 606\n",
      "Registros en SQL Server (DimProduct): 606\n",
      "\n",
      "================================================================================\n",
      "Mismo numero de registros: 606\n",
      "\n",
      "================================================================================\n",
      "COLUMNAS:\n",
      "\n",
      "PostgreSQL: ['productkey', 'productalternatekey', 'productsubcategorykey', 'weightunitmeasurecode', 'sizeunitmeasurecode', 'englishproductname', 'standardcost', 'finishedgoodsflag', 'color', 'safetystocklevel', 'reorderpoint', 'listprice', 'size', 'sizerange', 'weight', 'daystomanufacture', 'productline', 'dealerprice', 'class', 'style', 'modelname', 'largephoto', 'englishdescription', 'startdate', 'enddate', 'status']\n",
      "\n",
      "SQL Server: ['ProductKey', 'ProductAlternateKey', 'ProductSubcategoryKey', 'WeightUnitMeasureCode', 'SizeUnitMeasureCode', 'EnglishProductName', 'SpanishProductName', 'FrenchProductName', 'StandardCost', 'FinishedGoodsFlag', 'Color', 'SafetyStockLevel', 'ReorderPoint', 'ListPrice', 'Size', 'SizeRange', 'Weight', 'DaysToManufacture', 'ProductLine', 'DealerPrice', 'Class', 'Style', 'ModelName', 'LargePhoto', 'EnglishDescription', 'FrenchDescription', 'ChineseDescription', 'ArabicDescription', 'HebrewDescription', 'ThaiDescription', 'GermanDescription', 'JapaneseDescription', 'TurkishDescription', 'StartDate', 'EndDate', 'Status']\n",
      "\n",
      "================================================================================\n",
      "Columnas comunes para comparar: 26\n",
      "['class', 'color', 'daystomanufacture', 'dealerprice', 'enddate', 'englishdescription', 'englishproductname', 'finishedgoodsflag', 'largephoto', 'listprice', 'modelname', 'productalternatekey', 'productkey', 'productline', 'productsubcategorykey', 'reorderpoint', 'safetystocklevel', 'size', 'sizerange', 'sizeunitmeasurecode', 'standardcost', 'startdate', 'status', 'style', 'weight', 'weightunitmeasurecode']\n",
      "\n",
      "================================================================================\n",
      "COMPARACION DE DATOS:\n",
      "\n",
      "Diferencias en columna 'color': 254 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 0: PG='None' vs SS='NA'\n",
      "   - Fila 1: PG='None' vs SS='NA'\n",
      "   - Fila 2: PG='None' vs SS='NA'\n",
      "   - Fila 3: PG='None' vs SS='NA'\n",
      "   - Fila 4: PG='None' vs SS='NA'\n",
      "\n",
      "Diferencias en columna 'dealerprice': 308 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 211: PG='19.9915' vs SS='20.1865'\n",
      "   - Fila 212: PG='19.9915' vs SS='20.1865'\n",
      "   - Fila 213: PG='19.9915' vs SS='20.994'\n",
      "   - Fila 214: PG='20.0169' vs SS='20.1865'\n",
      "   - Fila 215: PG='20.0169' vs SS='20.1865'\n",
      "\n",
      "Diferencias en columna 'enddate': 200 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 211: PG='2012-05-29 00:00:00+00:00' vs SS='2007-12-28 00:00:00'\n",
      "   - Fila 212: PG='2013-05-29 00:00:00+00:00' vs SS='2008-12-27 00:00:00'\n",
      "   - Fila 214: PG='2012-05-29 00:00:00+00:00' vs SS='2007-12-28 00:00:00'\n",
      "   - Fila 215: PG='2013-05-29 00:00:00+00:00' vs SS='2008-12-27 00:00:00'\n",
      "   - Fila 217: PG='2012-05-29 00:00:00+00:00' vs SS='2007-12-28 00:00:00'\n",
      "\n",
      "Diferencias en columna 'englishdescription': 210 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 0: PG='' vs SS='None'\n",
      "   - Fila 1: PG='' vs SS='None'\n",
      "   - Fila 2: PG='' vs SS='None'\n",
      "   - Fila 3: PG='' vs SS='None'\n",
      "   - Fila 4: PG='' vs SS='None'\n",
      "\n",
      "Diferencias en columna 'largephoto': 606 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 0: PG='\\x474946383961f0009500f700000000008000000080008080' vs SS='b'GIF89a\\xf0\\x00\\x95\\x00\\xf7\\x00\\x00\\x00\\x00\\x00\\x'\n",
      "   - Fila 1: PG='\\x474946383961f0009500f700000000008000000080008080' vs SS='b'GIF89a\\xf0\\x00\\x95\\x00\\xf7\\x00\\x00\\x00\\x00\\x00\\x'\n",
      "   - Fila 2: PG='\\x474946383961f0009500f700000000008000000080008080' vs SS='b'GIF89a\\xf0\\x00\\x95\\x00\\xf7\\x00\\x00\\x00\\x00\\x00\\x'\n",
      "   - Fila 3: PG='\\x474946383961f0009500f700000000008000000080008080' vs SS='b'GIF89a\\xf0\\x00\\x95\\x00\\xf7\\x00\\x00\\x00\\x00\\x00\\x'\n",
      "   - Fila 4: PG='\\x474946383961f0009500f700000000008000000080008080' vs SS='b'GIF89a\\xf0\\x00\\x95\\x00\\xf7\\x00\\x00\\x00\\x00\\x00\\x'\n",
      "\n",
      "Diferencias en columna 'listprice': 12 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 295: PG='1191.174' vs SS='1191.1739'\n",
      "   - Fila 296: PG='1226.909' vs SS='1226.9091'\n",
      "   - Fila 300: PG='1191.174' vs SS='1191.1739'\n",
      "   - Fila 301: PG='1226.909' vs SS='1226.9091'\n",
      "   - Fila 303: PG='1191.174' vs SS='1191.1739'\n",
      "\n",
      "Diferencias en columna 'sizerange': 218 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 209: PG='58-60 CM' vs SS='54-58 CM'\n",
      "   - Fila 210: PG='58-60 CM' vs SS='54-58 CM'\n",
      "   - Fila 237: PG='62-64 CM' vs SS='60-62 CM'\n",
      "   - Fila 238: PG='62-64 CM' vs SS='60-62 CM'\n",
      "   - Fila 239: PG='62-64 CM' vs SS='60-62 CM'\n",
      "\n",
      "Diferencias en columna 'standardcost': 313 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 0: PG='0.0' vs SS='nan'\n",
      "   - Fila 1: PG='0.0' vs SS='nan'\n",
      "   - Fila 2: PG='0.0' vs SS='nan'\n",
      "   - Fila 3: PG='0.0' vs SS='nan'\n",
      "   - Fila 4: PG='0.0' vs SS='nan'\n",
      "\n",
      "Diferencias en columna 'startdate': 606 registros diferentes\n",
      "   Ejemplos (primeros 5):\n",
      "   - Fila 0: PG='NaT' vs SS='2003-07-01 00:00:00'\n",
      "   - Fila 1: PG='NaT' vs SS='2003-07-01 00:00:00'\n",
      "   - Fila 2: PG='NaT' vs SS='2003-07-01 00:00:00'\n",
      "   - Fila 3: PG='NaT' vs SS='2003-07-01 00:00:00'\n",
      "   - Fila 4: PG='NaT' vs SS='2003-07-01 00:00:00'\n",
      "\n",
      "================================================================================\n",
      "Se encontraron diferencias entre las tablas.\n",
      "Total de filas con diferencias: 2727\n",
      "\n",
      "Ejemplos de diferencias encontradas (primeros 5):\n",
      " - Fila Index: 0, ProductKey: 1, Columna: color, PostgreSQL: 'None' vs SQL Server: 'NA'\n",
      " - Fila Index: 1, ProductKey: 2, Columna: color, PostgreSQL: 'None' vs SQL Server: 'NA'\n",
      " - Fila Index: 2, ProductKey: 3, Columna: color, PostgreSQL: 'None' vs SQL Server: 'NA'\n",
      " - Fila Index: 3, ProductKey: 4, Columna: color, PostgreSQL: 'None' vs SQL Server: 'NA'\n",
      " - Fila Index: 4, ProductKey: 5, Columna: color, PostgreSQL: 'None' vs SQL Server: 'NA'\n",
      "\n",
      "================================================================================\n",
      "\n",
      "MUESTRA DE DATOS (primeras 3 filas):\n",
      "\n",
      "PostgreSQL (dim_product):\n",
      "   productkey productalternatekey  productsubcategorykey  \\\n",
      "0           1             AR-5381                    NaN   \n",
      "1           2             BA-8327                    NaN   \n",
      "2           3             BE-2349                    NaN   \n",
      "\n",
      "  weightunitmeasurecode sizeunitmeasurecode englishproductname  standardcost  \\\n",
      "0                  None                None    Adjustable Race           0.0   \n",
      "1                  None                None       Bearing Ball           0.0   \n",
      "2                  None                None    BB Ball Bearing           0.0   \n",
      "\n",
      "   finishedgoodsflag color  safetystocklevel  reorderpoint  listprice  size  \\\n",
      "0              False  None              1000           750        NaN  None   \n",
      "1              False  None              1000           750        NaN  None   \n",
      "2              False  None               800           600        NaN  None   \n",
      "\n",
      "  sizerange  weight  daystomanufacture productline  dealerprice class style  \\\n",
      "0        NA     NaN                  0        None          NaN  None  None   \n",
      "1        NA     NaN                  0        None          NaN  None  None   \n",
      "2        NA     NaN                  1        None          NaN  None  None   \n",
      "\n",
      "  modelname                                         largephoto  \\\n",
      "0      None  \\x474946383961f0009500f70000000000800000008000...   \n",
      "1      None  \\x474946383961f0009500f70000000000800000008000...   \n",
      "2      None  \\x474946383961f0009500f70000000000800000008000...   \n",
      "\n",
      "  englishdescription startdate enddate   status  \n",
      "0                          NaT     NaT  Current  \n",
      "1                          NaT     NaT  Current  \n",
      "2                          NaT     NaT  Current  \n",
      "\n",
      "SQL Server (DimProduct):\n",
      "   ProductKey ProductAlternateKey  ProductSubcategoryKey  \\\n",
      "0           1             AR-5381                    NaN   \n",
      "1           2             BA-8327                    NaN   \n",
      "2           3             BE-2349                    NaN   \n",
      "\n",
      "  WeightUnitMeasureCode SizeUnitMeasureCode EnglishProductName  \\\n",
      "0                  None                None    Adjustable Race   \n",
      "1                  None                None       Bearing Ball   \n",
      "2                  None                None    BB Ball Bearing   \n",
      "\n",
      "  SpanishProductName FrenchProductName  StandardCost  FinishedGoodsFlag Color  \\\n",
      "0                                                NaN              False    NA   \n",
      "1                                                NaN              False    NA   \n",
      "2                                                NaN              False    NA   \n",
      "\n",
      "   SafetyStockLevel  ReorderPoint  ListPrice  Size SizeRange  Weight  \\\n",
      "0              1000           750        NaN  None        NA     NaN   \n",
      "1              1000           750        NaN  None        NA     NaN   \n",
      "2               800           600        NaN  None        NA     NaN   \n",
      "\n",
      "   DaysToManufacture ProductLine  DealerPrice Class Style ModelName  \\\n",
      "0                  0        None          NaN  None  None      None   \n",
      "1                  0        None          NaN  None  None      None   \n",
      "2                  1        None          NaN  None  None      None   \n",
      "\n",
      "                                          LargePhoto EnglishDescription  \\\n",
      "0  b'GIF89a\\xf0\\x00\\x95\\x00\\xf7\\x00\\x00\\x00\\x00\\x...               None   \n",
      "1  b'GIF89a\\xf0\\x00\\x95\\x00\\xf7\\x00\\x00\\x00\\x00\\x...               None   \n",
      "2  b'GIF89a\\xf0\\x00\\x95\\x00\\xf7\\x00\\x00\\x00\\x00\\x...               None   \n",
      "\n",
      "  FrenchDescription ChineseDescription ArabicDescription HebrewDescription  \\\n",
      "0              None               None              None              None   \n",
      "1              None               None              None              None   \n",
      "2              None               None              None              None   \n",
      "\n",
      "  ThaiDescription GermanDescription JapaneseDescription TurkishDescription  \\\n",
      "0            None              None                None               None   \n",
      "1            None              None                None               None   \n",
      "2            None              None                None               None   \n",
      "\n",
      "   StartDate EndDate   Status  \n",
      "0 2003-07-01     NaT  Current  \n",
      "1 2003-07-01     NaT  Current  \n",
      "2 2003-07-01     NaT  Current  \n"
     ]
    }
   ],
   "source": [
    "# Verificar que los datos en dim_product (postgres) y DimProduct (sqlserver) sean iguales\n",
    "\n",
    "# Extraer datos de ambas bases de datos\n",
    "df_postgres_product = pd.read_sql(\"SELECT * FROM dim_product ORDER BY productkey\", engine_postgres)\n",
    "df_sqlserver_product = pd.read_sql(\"SELECT * FROM DimProduct ORDER BY ProductKey\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL (dim_product): {len(df_postgres_product)}\")\n",
    "print(f\"Registros en SQL Server (DimProduct): {len(df_sqlserver_product)}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Normalizar nombres de columnas para comparación (SQL Server usa PascalCase, Postgres usa snake_case)\n",
    "df_sqlserver_normalized = df_sqlserver_product.copy()\n",
    "df_sqlserver_normalized.columns = df_sqlserver_normalized.columns.str.lower()\n",
    "\n",
    "# Verificar si tienen el mismo número de registros\n",
    "if len(df_postgres_product) != len(df_sqlserver_normalized):\n",
    "    print(f\"ADVERTENCIA: Diferente numero de registros!\")\n",
    "    print(f\"   PostgreSQL: {len(df_postgres_product)} registros\")\n",
    "    print(f\"   SQL Server: {len(df_sqlserver_normalized)} registros\")\n",
    "else:\n",
    "    print(f\"Mismo numero de registros: {len(df_postgres_product)}\")\n",
    "\n",
    "# Verificar columnas\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"COLUMNAS:\")\n",
    "print(f\"\\nPostgreSQL: {list(df_postgres_product.columns)}\")\n",
    "print(f\"\\nSQL Server: {list(df_sqlserver_product.columns)}\")\n",
    "\n",
    "# Comparar columnas comunes\n",
    "common_cols = set(df_postgres_product.columns) & set(df_sqlserver_normalized.columns)\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Columnas comunes para comparar: {len(common_cols)}\")\n",
    "print(f\"{sorted(common_cols)}\")\n",
    "\n",
    "# Lista para almacenar las filas con diferencias\n",
    "rows_with_differences = []\n",
    "\n",
    "# Realizar comparación detallada si tienen las mismas columnas\n",
    "if len(common_cols) > 0:\n",
    "    # Ordenar por clave primaria y resetear índice\n",
    "    df_pg_sorted = df_postgres_product.sort_values('productkey').reset_index(drop=True)\n",
    "    df_ss_sorted = df_sqlserver_normalized.sort_values('productkey').reset_index(drop=True)\n",
    "    \n",
    "    # Seleccionar solo columnas comunes\n",
    "    df_pg_compare = df_pg_sorted[sorted(common_cols)]\n",
    "    df_ss_compare = df_ss_sorted[sorted(common_cols)]\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"COMPARACION DE DATOS:\")\n",
    "    \n",
    "    # Comparar valores\n",
    "    differences_found = False\n",
    "    for col in sorted(common_cols):\n",
    "        try:\n",
    "            # Convertir a string para comparación más robusta (maneja NaN, tipos diferentes, etc.)\n",
    "            # Usar errors='ignore' para manejar problemas de encoding\n",
    "            pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"\\nDiferencias en columna '{col}': {diff_count} registros diferentes\")\n",
    "                \n",
    "                # Guardar información de diferencias\n",
    "                diff_mask = pg_values != ss_values\n",
    "                if diff_mask.any():\n",
    "                    print(f\"   Ejemplos (primeros 5):\")\n",
    "                    diff_indices = diff_mask[diff_mask].index[:5]\n",
    "                    for idx in diff_indices:\n",
    "                        pg_val = str(df_pg_compare.loc[idx, col])[:50]\n",
    "                        ss_val = str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')[:50]\n",
    "                        print(f\"   - Fila {idx}: PG='{pg_val}' vs SS='{ss_val}'\")\n",
    "                    \n",
    "                    # Agregar todas las filas con diferencias en esta columna\n",
    "                    for idx in diff_mask[diff_mask].index:\n",
    "                        row_diff = {\n",
    "                            'fila_index': idx,\n",
    "                            'productkey': df_pg_compare.loc[idx, 'productkey'],\n",
    "                            'columna_diferente': col,\n",
    "                            'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                            'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                        }\n",
    "                        rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError al comparar columna '{col}': {str(e)}\")\n",
    "            print(f\"   Tipo en PostgreSQL: {df_pg_compare[col].dtype}\")\n",
    "            print(f\"   Tipo en SQL Server: {df_ss_compare[col].dtype}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"\\nLOS DATOS SON IDENTICOS! Todas las columnas comunes coinciden perfectamente.\")\n",
    "    else:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"Se encontraron diferencias entre las tablas.\")\n",
    "        print(f\"Total de filas con diferencias: {len(rows_with_differences)}\")\n",
    "        # Mostrar algunas diferencias encontradas\n",
    "        print(\"\\nEjemplos de diferencias encontradas (primeros 5):\")\n",
    "        for diff in rows_with_differences[:5]:\n",
    "            print(f\" - Fila Index: {diff['fila_index']}, ProductKey: {diff['productkey']}, Columna: {diff['columna_diferente']}, \"\n",
    "                  f\"PostgreSQL: '{diff['valor_postgres']}' vs SQL Server: '{diff['valor_sqlserver']}'\")\n",
    "else:\n",
    "    print(\"\\nNo se encontraron columnas comunes para comparar.\")\n",
    "\n",
    "# Mostrar muestra de datos\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"\\nMUESTRA DE DATOS (primeras 3 filas):\")\n",
    "print(\"\\nPostgreSQL (dim_product):\")\n",
    "print(df_postgres_product.head(3))\n",
    "print(\"\\nSQL Server (DimProduct):\")\n",
    "# Manejar posibles problemas de encoding en la visualización\n",
    "try:\n",
    "    print(df_sqlserver_product.head(3))\n",
    "except:\n",
    "    # Si hay problemas de encoding, mostrar con columnas específicas\n",
    "    print(\"(Nota: Algunos caracteres pueden no mostrarse correctamente debido a problemas de encoding)\")\n",
    "    for col in df_sqlserver_product.columns:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(df_sqlserver_product[col].head(3).apply(lambda x: str(x).encode('utf-8', errors='replace').decode('utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "bf77bc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 3652 | SQL Server: 3652\n",
      "Columnas comunes: 19\n",
      "LOS DATOS SON IDENTICOS!\n"
     ]
    }
   ],
   "source": [
    "# Comparar dim_date (postgres) vs DimDate (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM dim_date ORDER BY datekey\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM DimDate ORDER BY DateKey\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "if len(common_cols) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values('datekey').reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values('datekey').reset_index(drop=True)\n",
    "    \n",
    "    df_pg_compare = df_pg_sorted[sorted(common_cols)]\n",
    "    df_ss_compare = df_ss_sorted[sorted(common_cols)]\n",
    "    \n",
    "    differences_found = False\n",
    "    for col in sorted(common_cols):\n",
    "        try:\n",
    "            pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                \n",
    "                diff_mask = pg_values != ss_values\n",
    "                for idx in diff_mask[diff_mask].index:\n",
    "                    row_diff = {\n",
    "                        'tabla': 'dim_date',\n",
    "                        'fila_index': idx,\n",
    "                        'datekey': df_pg_compare.loc[idx, 'datekey'],\n",
    "                        'columna_diferente': col,\n",
    "                        'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                        'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                    }\n",
    "                    rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"Error en columna '{col}': {str(e)}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"LOS DATOS SON IDENTICOS!\")\n",
    "    else:\n",
    "        if rows_with_differences:\n",
    "            df_diff = pd.DataFrame(rows_with_differences)\n",
    "            csv_file = 'diferencias_dim_date.csv'\n",
    "            df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "            print(f\"Filas unicas con diferencias: {df_diff['fila_index'].nunique()}\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "1bd82e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 10 | SQL Server: 11\n",
      "Columnas comunes: 5\n",
      "\n",
      "ADVERTENCIA: Diferente cantidad de registros!\n",
      "Diferencia: 1 registros\n",
      "Claves solo en SQL Server: [11]\n",
      "\n",
      "Comparando 10 claves comunes...\n",
      "LOS DATOS SON IDENTICOS en las claves comunes!\n"
     ]
    }
   ],
   "source": [
    "# Comparar dim_salesterritory (postgres) vs DimSalesTerritory (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM dim_salesterritory ORDER BY salesterritorykey\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM DimSalesTerritory ORDER BY SalesTerritoryKey\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "# Verificar si tienen diferente cantidad de registros\n",
    "if len(df_pg) != len(df_ss):\n",
    "    print(f\"\\nADVERTENCIA: Diferente cantidad de registros!\")\n",
    "    print(f\"Diferencia: {abs(len(df_pg) - len(df_ss))} registros\")\n",
    "    \n",
    "    # Encontrar claves que están en una tabla pero no en la otra\n",
    "    pg_keys = set(df_pg['salesterritorykey'])\n",
    "    ss_keys = set(df_ss['salesterritorykey'])\n",
    "    \n",
    "    only_pg = pg_keys - ss_keys\n",
    "    only_ss = ss_keys - pg_keys\n",
    "    \n",
    "    if only_pg:\n",
    "        print(f\"\\nClaves solo en PostgreSQL: {sorted(only_pg)}\")\n",
    "    if only_ss:\n",
    "        print(f\"Claves solo en SQL Server: {sorted(only_ss)}\")\n",
    "\n",
    "if len(common_cols) > 0 and len(df_pg) > 0 and len(df_ss) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values('salesterritorykey').reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values('salesterritorykey').reset_index(drop=True)\n",
    "    \n",
    "    # Comparar solo las claves que existen en ambas tablas\n",
    "    common_keys = set(df_pg_sorted['salesterritorykey']) & set(df_ss_sorted['salesterritorykey'])\n",
    "    \n",
    "    if len(common_keys) > 0:\n",
    "        df_pg_compare = df_pg_sorted[df_pg_sorted['salesterritorykey'].isin(common_keys)].reset_index(drop=True)\n",
    "        df_ss_compare = df_ss_sorted[df_ss_sorted['salesterritorykey'].isin(common_keys)].reset_index(drop=True)\n",
    "        \n",
    "        print(f\"\\nComparando {len(common_keys)} claves comunes...\")\n",
    "        \n",
    "        differences_found = False\n",
    "        for col in sorted(common_cols):\n",
    "            try:\n",
    "                pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "                ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "                \n",
    "                if not pg_values.equals(ss_values):\n",
    "                    differences_found = True\n",
    "                    diff_count = (pg_values != ss_values).sum()\n",
    "                    print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                    \n",
    "                    diff_mask = pg_values != ss_values\n",
    "                    for idx in diff_mask[diff_mask].index:\n",
    "                        row_diff = {\n",
    "                            'tabla': 'dim_salesterritory',\n",
    "                            'fila_index': idx,\n",
    "                            'salesterritorykey': df_pg_compare.loc[idx, 'salesterritorykey'],\n",
    "                            'columna_diferente': col,\n",
    "                            'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                            'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                        }\n",
    "                        rows_with_differences.append(row_diff)\n",
    "            except Exception as e:\n",
    "                print(f\"Error en columna '{col}': {str(e)}\")\n",
    "        \n",
    "        if not differences_found:\n",
    "            print(\"LOS DATOS SON IDENTICOS en las claves comunes!\")\n",
    "        else:\n",
    "            if rows_with_differences:\n",
    "                df_diff = pd.DataFrame(rows_with_differences)\n",
    "                csv_file = 'diferencias_dim_salesterritory.csv'\n",
    "                df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "                print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "                print(f\"Filas unicas con diferencias: {df_diff['fila_index'].nunique()}\")\n",
    "    else:\n",
    "        print(\"\\nNo hay claves comunes para comparar\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "55048d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 10 | SQL Server: 10\n",
      "Columnas comunes: 3\n",
      "LOS DATOS SON IDENTICOS!\n"
     ]
    }
   ],
   "source": [
    "# Comparar dim_salesreason (postgres) vs DimSalesReason (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM dim_salesreason ORDER BY salesreasonkey\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM DimSalesReason ORDER BY SalesReasonKey\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "if len(common_cols) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values('salesreasonkey').reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values('salesreasonkey').reset_index(drop=True)\n",
    "    \n",
    "    df_pg_compare = df_pg_sorted[sorted(common_cols)]\n",
    "    df_ss_compare = df_ss_sorted[sorted(common_cols)]\n",
    "    \n",
    "    differences_found = False\n",
    "    for col in sorted(common_cols):\n",
    "        try:\n",
    "            pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                \n",
    "                diff_mask = pg_values != ss_values\n",
    "                for idx in diff_mask[diff_mask].index:\n",
    "                    row_diff = {\n",
    "                        'tabla': 'dim_salesreason',\n",
    "                        'fila_index': idx,\n",
    "                        'salesreasonkey': df_pg_compare.loc[idx, 'salesreasonkey'],\n",
    "                        'columna_diferente': col,\n",
    "                        'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                        'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                    }\n",
    "                    rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"Error en columna '{col}': {str(e)}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"LOS DATOS SON IDENTICOS!\")\n",
    "    else:\n",
    "        if rows_with_differences:\n",
    "            df_diff = pd.DataFrame(rows_with_differences)\n",
    "            csv_file = 'diferencias_dim_salesreason.csv'\n",
    "            df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "            print(f\"Filas unicas con diferencias: {df_diff['fila_index'].nunique()}\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "a86d9a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 16 | SQL Server: 16\n",
      "Columnas comunes: 4\n",
      "Diferencias en 'enddate': 16 registros\n",
      "Diferencias en 'startdate': 16 registros\n",
      "\n",
      "Exportadas 32 diferencias a: diferencias_dim_promotion.csv\n",
      "Filas unicas con diferencias: 16\n"
     ]
    }
   ],
   "source": [
    "# Comparar dim_promotion (postgres) vs DimPromotion (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM dim_promotion ORDER BY promotionkey\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM DimPromotion ORDER BY PromotionKey\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "if len(common_cols) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values('promotionkey').reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values('promotionkey').reset_index(drop=True)\n",
    "    \n",
    "    df_pg_compare = df_pg_sorted[sorted(common_cols)]\n",
    "    df_ss_compare = df_ss_sorted[sorted(common_cols)]\n",
    "    \n",
    "    differences_found = False\n",
    "    for col in sorted(common_cols):\n",
    "        try:\n",
    "            pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                \n",
    "                diff_mask = pg_values != ss_values\n",
    "                for idx in diff_mask[diff_mask].index:\n",
    "                    row_diff = {\n",
    "                        'tabla': 'dim_promotion',\n",
    "                        'fila_index': idx,\n",
    "                        'promotionkey': df_pg_compare.loc[idx, 'promotionkey'],\n",
    "                        'columna_diferente': col,\n",
    "                        'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                        'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                    }\n",
    "                    rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"Error en columna '{col}': {str(e)}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"LOS DATOS SON IDENTICOS!\")\n",
    "    else:\n",
    "        if rows_with_differences:\n",
    "            df_diff = pd.DataFrame(rows_with_differences)\n",
    "            csv_file = 'diferencias_dim_promotion.csv'\n",
    "            df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "            print(f\"Filas unicas con diferencias: {df_diff['fila_index'].nunique()}\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "e5b83ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 296 | SQL Server: 296\n",
      "Columnas comunes: 30\n",
      "\n",
      "Comparando 296 claves comunes...\n",
      "Diferencias en 'baserate': 112 registros\n",
      "Diferencias en 'birthdate': 296 registros\n",
      "Diferencias en 'departmentname': 69 registros\n",
      "Diferencias en 'emailaddress': 121 registros\n",
      "Diferencias en 'emergencycontactname': 121 registros\n",
      "Diferencias en 'emergencycontactphone': 121 registros\n",
      "Diferencias en 'employeenationalidalternatekey': 121 registros\n",
      "Diferencias en 'enddate': 11 registros\n",
      "Diferencias en 'firstname': 121 registros\n",
      "Diferencias en 'gender': 40 registros\n",
      "Diferencias en 'hiredate': 296 registros\n",
      "Diferencias en 'lastname': 121 registros\n",
      "Diferencias en 'loginid': 121 registros\n",
      "Diferencias en 'maritalstatus': 60 registros\n",
      "Diferencias en 'middlename': 112 registros\n",
      "Diferencias en 'parentemployeekey': 296 registros\n",
      "Diferencias en 'parentemployeenationalidalternatekey': 296 registros\n",
      "Diferencias en 'payfrequency': 72 registros\n",
      "Diferencias en 'phone': 121 registros\n",
      "Diferencias en 'salariedflag': 28 registros\n",
      "Diferencias en 'salespersonflag': 1 registros\n",
      "Diferencias en 'salesterritorykey': 2 registros\n",
      "Diferencias en 'sickleavehours': 119 registros\n",
      "Diferencias en 'startdate': 296 registros\n",
      "Diferencias en 'status': 295 registros\n",
      "Diferencias en 'title': 113 registros\n",
      "Diferencias en 'vacationhours': 121 registros\n",
      "\n",
      "Se encontraron diferencias en las claves comunes\n",
      "\n",
      "Exportadas 3603 diferencias a: diferencias_dim_employee.csv\n",
      "Filas unicas con diferencias: 296\n",
      "Registros solo en una BD: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Comparar dim_employee (postgres) vs DimEmployee (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM dim_employee ORDER BY employeekey\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM DimEmployee ORDER BY EmployeeKey\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "# Verificar si tienen diferente cantidad de registros\n",
    "if len(df_pg) != len(df_ss):\n",
    "    print(f\"\\nADVERTENCIA: Diferente cantidad de registros!\")\n",
    "    print(f\"Diferencia: {abs(len(df_pg) - len(df_ss))} registros\")\n",
    "    \n",
    "    # Encontrar claves que están en una tabla pero no en la otra\n",
    "    pg_keys = set(df_pg['employeekey'])\n",
    "    ss_keys = set(df_ss['employeekey'])\n",
    "    \n",
    "    only_pg = pg_keys - ss_keys\n",
    "    only_ss = ss_keys - pg_keys\n",
    "    \n",
    "    if only_pg:\n",
    "        print(f\"\\nClaves solo en PostgreSQL: {sorted(only_pg)}\")\n",
    "        # Agregar registros solo en PostgreSQL al archivo de diferencias\n",
    "        for key in only_pg:\n",
    "            rows_with_differences.append({\n",
    "                'tabla': 'dim_employee',\n",
    "                'fila_index': -1,\n",
    "                'employeekey': key,\n",
    "                'columna_diferente': 'REGISTRO_COMPLETO',\n",
    "                'valor_postgres': 'EXISTE',\n",
    "                'valor_sqlserver': 'NO_EXISTE'\n",
    "            })\n",
    "    \n",
    "    if only_ss:\n",
    "        print(f\"Claves solo en SQL Server: {sorted(only_ss)}\")\n",
    "        # Agregar registros solo en SQL Server al archivo de diferencias\n",
    "        for key in only_ss:\n",
    "            rows_with_differences.append({\n",
    "                'tabla': 'dim_employee',\n",
    "                'fila_index': -1,\n",
    "                'employeekey': key,\n",
    "                'columna_diferente': 'REGISTRO_COMPLETO',\n",
    "                'valor_postgres': 'NO_EXISTE',\n",
    "                'valor_sqlserver': 'EXISTE'\n",
    "            })\n",
    "\n",
    "if len(common_cols) > 0 and len(df_pg) > 0 and len(df_ss) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values('employeekey').reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values('employeekey').reset_index(drop=True)\n",
    "    \n",
    "    # Comparar solo las claves que existen en ambas tablas\n",
    "    common_keys = set(df_pg_sorted['employeekey']) & set(df_ss_sorted['employeekey'])\n",
    "    \n",
    "    if len(common_keys) > 0:\n",
    "        df_pg_compare = df_pg_sorted[df_pg_sorted['employeekey'].isin(common_keys)].reset_index(drop=True)\n",
    "        df_ss_compare = df_ss_sorted[df_ss_sorted['employeekey'].isin(common_keys)].reset_index(drop=True)\n",
    "        \n",
    "        print(f\"\\nComparando {len(common_keys)} claves comunes...\")\n",
    "        \n",
    "        differences_found = False\n",
    "        for col in sorted(common_cols):\n",
    "            try:\n",
    "                pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "                ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "                \n",
    "                if not pg_values.equals(ss_values):\n",
    "                    differences_found = True\n",
    "                    diff_count = (pg_values != ss_values).sum()\n",
    "                    print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                    \n",
    "                    diff_mask = pg_values != ss_values\n",
    "                    for idx in diff_mask[diff_mask].index:\n",
    "                        row_diff = {\n",
    "                            'tabla': 'dim_employee',\n",
    "                            'fila_index': idx,\n",
    "                            'employeekey': df_pg_compare.loc[idx, 'employeekey'],\n",
    "                            'columna_diferente': col,\n",
    "                            'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                            'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                        }\n",
    "                        rows_with_differences.append(row_diff)\n",
    "            except Exception as e:\n",
    "                print(f\"Error en columna '{col}': {str(e)}\")\n",
    "        \n",
    "        if not differences_found:\n",
    "            print(\"LOS DATOS SON IDENTICOS en las claves comunes!\")\n",
    "        else:\n",
    "            print(f\"\\nSe encontraron diferencias en las claves comunes\")\n",
    "    else:\n",
    "        print(\"\\nNo hay claves comunes para comparar\")\n",
    "\n",
    "# Exportar diferencias a CSV (si las hay)\n",
    "if rows_with_differences:\n",
    "    df_diff = pd.DataFrame(rows_with_differences)\n",
    "    csv_file = 'diferencias_dim_employee.csv'\n",
    "    df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "    print(f\"Filas unicas con diferencias: {df_diff[df_diff['fila_index'] != -1]['fila_index'].nunique() if any(df_diff['fila_index'] != -1) else 0}\")\n",
    "    print(f\"Registros solo en una BD: {len(df_diff[df_diff['fila_index'] == -1])}\")\n",
    "else:\n",
    "    print(\"\\nNo se encontraron diferencias\")\n",
    "    \n",
    "print(\"\\nNo hay columnas comunes para comparar\" if len(common_cols) == 0 else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "36359126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 701 | SQL Server: 701\n",
      "Columnas comunes: 16\n",
      "Diferencias en 'addressline1': 26 registros\n",
      "Diferencias en 'annualrevenue': 701 registros\n",
      "Diferencias en 'annualsales': 701 registros\n",
      "Diferencias en 'businesstype': 470 registros\n",
      "Diferencias en 'geographykey': 22 registros\n",
      "Diferencias en 'minpaymentamount': 191 registros\n",
      "Diferencias en 'minpaymenttype': 569 registros\n",
      "Diferencias en 'phone': 38 registros\n",
      "Diferencias en 'resellername': 4 registros\n",
      "Diferencias en 'yearopened': 701 registros\n",
      "\n",
      "Exportadas 3423 diferencias a: diferencias_dim_reseller.csv\n",
      "Filas unicas con diferencias: 701\n"
     ]
    }
   ],
   "source": [
    "# Comparar dim_reseller (postgres) vs DimReseller (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM dim_reseller ORDER BY resellerkey\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM DimReseller ORDER BY ResellerKey\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "if len(common_cols) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values('resellerkey').reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values('resellerkey').reset_index(drop=True)\n",
    "    \n",
    "    df_pg_compare = df_pg_sorted[sorted(common_cols)]\n",
    "    df_ss_compare = df_ss_sorted[sorted(common_cols)]\n",
    "    \n",
    "    differences_found = False\n",
    "    for col in sorted(common_cols):\n",
    "        try:\n",
    "            pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                \n",
    "                diff_mask = pg_values != ss_values\n",
    "                for idx in diff_mask[diff_mask].index:\n",
    "                    row_diff = {\n",
    "                        'tabla': 'dim_reseller',\n",
    "                        'fila_index': idx,\n",
    "                        'resellerkey': df_pg_compare.loc[idx, 'resellerkey'],\n",
    "                        'columna_diferente': col,\n",
    "                        'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                        'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                    }\n",
    "                    rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"Error en columna '{col}': {str(e)}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"LOS DATOS SON IDENTICOS!\")\n",
    "    else:\n",
    "        if rows_with_differences:\n",
    "            df_diff = pd.DataFrame(rows_with_differences)\n",
    "            csv_file = 'diferencias_dim_reseller.csv'\n",
    "            df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "            print(f\"Filas unicas con diferencias: {df_diff['fila_index'].nunique()}\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "84ced963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 64515 | SQL Server: 64515\n",
      "Columnas comunes: 3\n",
      "LOS DATOS SON IDENTICOS!\n"
     ]
    }
   ],
   "source": [
    "# Comparar fact_internet_sales_reason (postgres) vs FactInternetSalesReason (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM fact_internet_sales_reason ORDER BY salesordernumber, salesorderlinenumber, salesreasonid\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM FactInternetSalesReason ORDER BY SalesOrderNumber, SalesOrderLineNumber, SalesReasonKey\", engine_sqlserver)\n",
    "\n",
    "# Rename salesreasonid to salesreasonkey in PostgreSQL dataframe for consistency\n",
    "df_pg.rename(columns={'salesreasonid': 'salesreasonkey'}, inplace=True)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "if len(common_cols) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values(['salesordernumber', 'salesorderlinenumber', 'salesreasonkey']).reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values(['salesordernumber', 'salesorderlinenumber', 'salesreasonkey']).reset_index(drop=True)\n",
    "    \n",
    "    df_pg_compare = df_pg_sorted[sorted(common_cols)]\n",
    "    df_ss_compare = df_ss_sorted[sorted(common_cols)]\n",
    "    \n",
    "    differences_found = False\n",
    "    for col in sorted(common_cols):\n",
    "        try:\n",
    "            pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                \n",
    "                diff_mask = pg_values != ss_values\n",
    "                for idx in diff_mask[diff_mask].index[:100]:  # Limitar a 100 diferencias por columna\n",
    "                    row_diff = {\n",
    "                        'tabla': 'fact_internet_sales_reason',\n",
    "                        'fila_index': idx,\n",
    "                        'salesordernumber': df_pg_compare.loc[idx, 'salesordernumber'],\n",
    "                        'salesorderlinenumber': df_pg_compare.loc[idx, 'salesorderlinenumber'],\n",
    "                        'salesreasonkey': df_pg_compare.loc[idx, 'salesreasonkey'],\n",
    "                        'columna_diferente': col,\n",
    "                        'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                        'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                    }\n",
    "                    rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"Error en columna '{col}': {str(e)}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"LOS DATOS SON IDENTICOS!\")\n",
    "    else:\n",
    "        if rows_with_differences:\n",
    "            df_diff = pd.DataFrame(rows_with_differences)\n",
    "            csv_file = 'diferencias_fact_internet_sales_reason.csv'\n",
    "            df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "            print(f\"Filas unicas con diferencias: {df_diff['fila_index'].nunique()}\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "b34f73b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 60398 | SQL Server: 60398\n",
      "Columnas comunes: 25\n",
      "Diferencias en 'duedate': 60398 registros\n",
      "Diferencias en 'duedatekey': 60398 registros\n",
      "Diferencias en 'extendedamount': 1075 registros\n",
      "Diferencias en 'freight': 50730 registros\n",
      "Diferencias en 'orderdate': 60398 registros\n",
      "Diferencias en 'orderdatekey': 60398 registros\n",
      "Diferencias en 'productkey': 16605 registros\n",
      "Diferencias en 'productstandardcost': 2449 registros\n",
      "Diferencias en 'salesamount': 1075 registros\n",
      "Diferencias en 'shipdate': 60398 registros\n",
      "Diferencias en 'shipdatekey': 60398 registros\n",
      "Diferencias en 'taxamt': 50730 registros\n",
      "Diferencias en 'totalproductcost': 2449 registros\n",
      "Diferencias en 'unitprice': 1075 registros\n",
      "\n",
      "Exportadas 1400 diferencias a: diferencias_fact_internet_sales.csv\n",
      "Filas unicas con diferencias: 491\n"
     ]
    }
   ],
   "source": [
    "# Comparar fact_internet_sales (postgres) vs FactInternetSales (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM fact_internet_sales ORDER BY salesordernumber, salesorderlinenumber\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM FactInternetSales ORDER BY SalesOrderNumber, SalesOrderLineNumber\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "if len(common_cols) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values(['salesordernumber', 'salesorderlinenumber']).reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values(['salesordernumber', 'salesorderlinenumber']).reset_index(drop=True)\n",
    "    \n",
    "    df_pg_compare = df_pg_sorted[sorted(common_cols)]\n",
    "    df_ss_compare = df_ss_sorted[sorted(common_cols)]\n",
    "    \n",
    "    differences_found = False\n",
    "    for col in sorted(common_cols):\n",
    "        try:\n",
    "            pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                \n",
    "                diff_mask = pg_values != ss_values\n",
    "                for idx in diff_mask[diff_mask].index[:100]:  # Limitar a 100 diferencias por columna\n",
    "                    row_diff = {\n",
    "                        'tabla': 'fact_internet_sales',\n",
    "                        'fila_index': idx,\n",
    "                        'salesordernumber': df_pg_compare.loc[idx, 'salesordernumber'],\n",
    "                        'salesorderlinenumber': df_pg_compare.loc[idx, 'salesorderlinenumber'],\n",
    "                        'columna_diferente': col,\n",
    "                        'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                        'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                    }\n",
    "                    rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"Error en columna '{col}': {str(e)}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"LOS DATOS SON IDENTICOS!\")\n",
    "    else:\n",
    "        if rows_with_differences:\n",
    "            df_diff = pd.DataFrame(rows_with_differences)\n",
    "            csv_file = 'diferencias_fact_internet_sales.csv'\n",
    "            df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "            print(f\"Filas unicas con diferencias: {df_diff['fila_index'].nunique()}\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "6796a9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 655 | SQL Server: 655\n",
      "Columnas comunes: 8\n",
      "Diferencias en 'city': 10 registros\n",
      "Diferencias en 'postalcode': 25 registros\n",
      "Diferencias en 'stateprovincecode': 565 registros\n",
      "\n",
      "Exportadas 600 diferencias a: diferencias_dim_geography.csv\n",
      "Filas unicas con diferencias: 590\n"
     ]
    }
   ],
   "source": [
    "# Comparar dim_geography (postgres) vs DimGeography (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM dim_geography ORDER BY geographykey\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM DimGeography ORDER BY GeographyKey\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "if len(common_cols) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values('geographykey').reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values('geographykey').reset_index(drop=True)\n",
    "    \n",
    "    df_pg_compare = df_pg_sorted[sorted(common_cols)]\n",
    "    df_ss_compare = df_ss_sorted[sorted(common_cols)]\n",
    "    \n",
    "    differences_found = False\n",
    "    for col in sorted(common_cols):\n",
    "        try:\n",
    "            pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                \n",
    "                diff_mask = pg_values != ss_values\n",
    "                for idx in diff_mask[diff_mask].index:\n",
    "                    row_diff = {\n",
    "                        'tabla': 'dim_geography',\n",
    "                        'fila_index': idx,\n",
    "                        'geographykey': df_pg_compare.loc[idx, 'geographykey'],\n",
    "                        'columna_diferente': col,\n",
    "                        'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                        'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                    }\n",
    "                    rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"Error en columna '{col}': {str(e)}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"LOS DATOS SON IDENTICOS!\")\n",
    "    else:\n",
    "        if rows_with_differences:\n",
    "            df_diff = pd.DataFrame(rows_with_differences)\n",
    "            csv_file = 'diferencias_dim_geography.csv'\n",
    "            df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "            print(f\"Filas unicas con diferencias: {df_diff['fila_index'].nunique()}\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "33231f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 18484 | SQL Server: 18484\n",
      "Columnas comunes: 21\n",
      "Diferencias en 'addressline1': 2 registros\n",
      "Diferencias en 'birthdate': 18484 registros\n",
      "Diferencias en 'datefirstpurchase': 18484 registros\n",
      "Diferencias en 'geographykey': 850 registros\n",
      "Diferencias en 'yearlyincome': 18484 registros\n",
      "\n",
      "Exportadas 56304 diferencias a: diferencias_dim_customer.csv\n",
      "Filas unicas con diferencias: 18484\n"
     ]
    }
   ],
   "source": [
    "# Comparar dim_customer (postgres) vs DimCustomer (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM dim_customer ORDER BY customerkey\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM DimCustomer ORDER BY CustomerKey\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "if len(common_cols) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values('customerkey').reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values('customerkey').reset_index(drop=True)\n",
    "    \n",
    "    df_pg_compare = df_pg_sorted[sorted(common_cols)]\n",
    "    df_ss_compare = df_ss_sorted[sorted(common_cols)]\n",
    "    \n",
    "    differences_found = False\n",
    "    for col in sorted(common_cols):\n",
    "        try:\n",
    "            pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                \n",
    "                diff_mask = pg_values != ss_values\n",
    "                for idx in diff_mask[diff_mask].index:\n",
    "                    row_diff = {\n",
    "                        'tabla': 'dim_customer',\n",
    "                        'fila_index': idx,\n",
    "                        'customerkey': df_pg_compare.loc[idx, 'customerkey'],\n",
    "                        'columna_diferente': col,\n",
    "                        'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                        'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                    }\n",
    "                    rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"Error en columna '{col}': {str(e)}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"LOS DATOS SON IDENTICOS!\")\n",
    "    else:\n",
    "        if rows_with_differences:\n",
    "            df_diff = pd.DataFrame(rows_with_differences)\n",
    "            csv_file = 'diferencias_dim_customer.csv'\n",
    "            df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "            print(f\"Filas unicas con diferencias: {df_diff['fila_index'].nunique()}\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "5e984182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 105 | SQL Server: 105\n",
      "Columnas comunes: 3\n",
      "Diferencias en 'currencyname': 105 registros\n",
      "\n",
      "Exportadas 105 diferencias a: diferencias_dim_currency.csv\n",
      "Filas unicas con diferencias: 105\n"
     ]
    }
   ],
   "source": [
    "# Comparar dim_currency (postgres) vs DimCurrency (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM dim_currency ORDER BY currencykey\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM DimCurrency ORDER BY CurrencyKey\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "if len(common_cols) > 0:\n",
    "    df_pg_sorted = df_pg.sort_values('currencykey').reset_index(drop=True)\n",
    "    df_ss_sorted = df_ss.sort_values('currencykey').reset_index(drop=True)\n",
    "    \n",
    "    df_pg_compare = df_pg_sorted[sorted(common_cols)]\n",
    "    df_ss_compare = df_ss_sorted[sorted(common_cols)]\n",
    "    \n",
    "    differences_found = False\n",
    "    for col in sorted(common_cols):\n",
    "        try:\n",
    "            pg_values = df_pg_compare[col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = df_ss_compare[col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                \n",
    "                diff_mask = pg_values != ss_values\n",
    "                for idx in diff_mask[diff_mask].index:\n",
    "                    row_diff = {\n",
    "                        'tabla': 'dim_currency',\n",
    "                        'fila_index': idx,\n",
    "                        'currencykey': df_pg_compare.loc[idx, 'currencykey'],\n",
    "                        'columna_diferente': col,\n",
    "                        'valor_postgres': str(df_pg_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8'),\n",
    "                        'valor_sqlserver': str(df_ss_compare.loc[idx, col]).encode('utf-8', errors='ignore').decode('utf-8')\n",
    "                    }\n",
    "                    rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"Error en columna '{col}': {str(e)}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"LOS DATOS SON IDENTICOS!\")\n",
    "    else:\n",
    "        if rows_with_differences:\n",
    "            df_diff = pd.DataFrame(rows_with_differences)\n",
    "            csv_file = 'diferencias_dim_currency.csv'\n",
    "            df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nExportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "            print(f\"Filas unicas con diferencias: {df_diff['fila_index'].nunique()}\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "04c5b031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en PostgreSQL: 60855 | SQL Server: 60855\n",
      "Columnas comunes: 27\n",
      "\n",
      "📊 Comparando 60855 registros comunes...\n",
      "Diferencias en 'discountamount': 2818 registros\n",
      "Diferencias en 'duedate': 60855 registros\n",
      "Diferencias en 'duedatekey': 60855 registros\n",
      "Diferencias en 'employeekey': 3189 registros\n",
      "Diferencias en 'extendedamount': 5517 registros\n",
      "Diferencias en 'freight': 60840 registros\n",
      "Diferencias en 'orderdate': 60855 registros\n",
      "Diferencias en 'orderdatekey': 60855 registros\n",
      "Diferencias en 'productstandardcost': 14323 registros\n",
      "Diferencias en 'salesamount': 7664 registros\n",
      "Diferencias en 'shipdate': 60855 registros\n",
      "Diferencias en 'shipdatekey': 60855 registros\n",
      "Diferencias en 'taxamt': 60840 registros\n",
      "Diferencias en 'totalproductcost': 19895 registros\n",
      "Diferencias en 'unitprice': 18 registros\n",
      "\n",
      "⚠️  Se encontraron diferencias en los valores\n",
      "\n",
      "📝 Exportadas 1418 diferencias a: diferencias_fact_reseller_sales.csv\n",
      "   - Diferencias en valores: 1418\n"
     ]
    }
   ],
   "source": [
    "# Comparar fact_reseller_sales (postgres) vs FactResellerSales (sqlserver)\n",
    "\n",
    "df_pg = pd.read_sql(\"SELECT * FROM fact_reseller_sales ORDER BY salesordernumber, salesorderlinenumber\", engine_postgres)\n",
    "df_ss = pd.read_sql(\"SELECT * FROM FactResellerSales ORDER BY SalesOrderNumber, SalesOrderLineNumber\", engine_sqlserver)\n",
    "\n",
    "print(f\"Registros en PostgreSQL: {len(df_pg)} | SQL Server: {len(df_ss)}\")\n",
    "\n",
    "df_ss.columns = df_ss.columns.str.lower()\n",
    "common_cols = set(df_pg.columns) & set(df_ss.columns)\n",
    "print(f\"Columnas comunes: {len(common_cols)}\")\n",
    "\n",
    "rows_with_differences = []\n",
    "\n",
    "# Verificar diferencia en cantidad de registros\n",
    "diff_count = abs(len(df_pg) - len(df_ss))\n",
    "if diff_count > 0:\n",
    "    print(f\"\\n⚠️  ADVERTENCIA: Hay {diff_count} registros de diferencia en el conteo total\")\n",
    "    \n",
    "    # Identificar registros únicos en cada base de datos\n",
    "    pg_keys = set(df_pg.apply(lambda x: f\"{x['salesordernumber']}-{x['salesorderlinenumber']}\", axis=1))\n",
    "    ss_keys = set(df_ss.apply(lambda x: f\"{x['salesordernumber']}-{x['salesorderlinenumber']}\", axis=1))\n",
    "    \n",
    "    only_pg = pg_keys - ss_keys\n",
    "    only_ss = ss_keys - pg_keys\n",
    "    \n",
    "    if only_pg:\n",
    "        print(f\"   Registros SOLO en PostgreSQL: {len(only_pg)}\")\n",
    "        for key in list(only_pg)[:5]:  # Mostrar solo los primeros 5\n",
    "            rows_with_differences.append({\n",
    "                'tabla': 'fact_reseller_sales',\n",
    "                'salesordernumber': key.split('-')[0],\n",
    "                'salesorderlinenumber': key.split('-')[1],\n",
    "                'columna_diferente': 'REGISTRO_COMPLETO',\n",
    "                'valor_postgres': 'EXISTE',\n",
    "                'valor_sqlserver': 'NO_EXISTE'\n",
    "            })\n",
    "    \n",
    "    if only_ss:\n",
    "        print(f\"   Registros SOLO en SQL Server: {len(only_ss)}\")\n",
    "        for key in list(only_ss)[:5]:  # Mostrar solo los primeros 5\n",
    "            rows_with_differences.append({\n",
    "                'tabla': 'fact_reseller_sales',\n",
    "                'salesordernumber': key.split('-')[0],\n",
    "                'salesorderlinenumber': key.split('-')[1],\n",
    "                'columna_diferente': 'REGISTRO_COMPLETO',\n",
    "                'valor_postgres': 'NO_EXISTE',\n",
    "                'valor_sqlserver': 'EXISTE'\n",
    "            })\n",
    "\n",
    "# Comparar solo los registros que existen en ambas bases de datos\n",
    "if len(common_cols) > 0:\n",
    "    # Crear una clave compuesta para hacer merge\n",
    "    df_pg['_merge_key'] = df_pg['salesordernumber'] + '-' + df_pg['salesorderlinenumber'].astype(str)\n",
    "    df_ss['_merge_key'] = df_ss['salesordernumber'] + '-' + df_ss['salesorderlinenumber'].astype(str)\n",
    "    \n",
    "    # Hacer merge inner para comparar solo registros comunes\n",
    "    merged = df_pg.merge(\n",
    "        df_ss,\n",
    "        on='_merge_key',\n",
    "        how='inner',\n",
    "        suffixes=('_pg', '_ss')\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n📊 Comparando {len(merged)} registros comunes...\")\n",
    "    \n",
    "    differences_found = False\n",
    "    cols_to_compare = [col for col in common_cols if col not in ['salesordernumber', 'salesorderlinenumber']]\n",
    "    \n",
    "    for col in sorted(cols_to_compare):\n",
    "        try:\n",
    "            pg_col = f\"{col}_pg\" if f\"{col}_pg\" in merged.columns else col\n",
    "            ss_col = f\"{col}_ss\" if f\"{col}_ss\" in merged.columns else col\n",
    "            \n",
    "            if pg_col not in merged.columns or ss_col not in merged.columns:\n",
    "                continue\n",
    "            \n",
    "            pg_values = merged[pg_col].apply(lambda x: str(x) if pd.notna(x) else 'NaN')\n",
    "            ss_values = merged[ss_col].apply(lambda x: str(x).encode('utf-8', errors='ignore').decode('utf-8') if pd.notna(x) else 'NaN')\n",
    "            \n",
    "            if not pg_values.equals(ss_values):\n",
    "                differences_found = True\n",
    "                diff_count = (pg_values != ss_values).sum()\n",
    "                print(f\"Diferencias en '{col}': {diff_count} registros\")\n",
    "                \n",
    "                diff_mask = pg_values != ss_values\n",
    "                for idx in diff_mask[diff_mask].index[:100]:  # Limitar a 100 diferencias por columna\n",
    "                    row_diff = {\n",
    "                        'tabla': 'fact_reseller_sales',\n",
    "                        'salesordernumber': merged.loc[idx, 'salesordernumber_pg'] if 'salesordernumber_pg' in merged.columns else merged.loc[idx, 'salesordernumber'],\n",
    "                        'salesorderlinenumber': merged.loc[idx, 'salesorderlinenumber_pg'] if 'salesorderlinenumber_pg' in merged.columns else merged.loc[idx, 'salesorderlinenumber'],\n",
    "                        'columna_diferente': col,\n",
    "                        'valor_postgres': str(merged.loc[idx, pg_col]).encode('utf-8', errors='ignore').decode('utf-8')[:100],\n",
    "                        'valor_sqlserver': str(merged.loc[idx, ss_col]).encode('utf-8', errors='ignore').decode('utf-8')[:100]\n",
    "                    }\n",
    "                    rows_with_differences.append(row_diff)\n",
    "        except Exception as e:\n",
    "            print(f\"Error en columna '{col}': {str(e)}\")\n",
    "    \n",
    "    if not differences_found:\n",
    "        print(\"\\n✅ LOS DATOS SON IDENTICOS en los registros comunes!\")\n",
    "    else:\n",
    "        print(f\"\\n⚠️  Se encontraron diferencias en los valores\")\n",
    "    \n",
    "    # Exportar diferencias a CSV\n",
    "    if rows_with_differences:\n",
    "        df_diff = pd.DataFrame(rows_with_differences)\n",
    "        csv_file = 'diferencias_fact_reseller_sales.csv'\n",
    "        df_diff.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\n📝 Exportadas {len(rows_with_differences)} diferencias a: {csv_file}\")\n",
    "        \n",
    "        # Contar tipos de diferencias\n",
    "        value_diffs = len(df_diff[df_diff['columna_diferente'] != 'REGISTRO_COMPLETO'])\n",
    "        record_diffs = len(df_diff[df_diff['columna_diferente'] == 'REGISTRO_COMPLETO'])\n",
    "        \n",
    "        if value_diffs > 0:\n",
    "            print(f\"   - Diferencias en valores: {value_diffs}\")\n",
    "        if record_diffs > 0:\n",
    "            print(f\"   - Registros únicos: {record_diffs}\")\n",
    "else:\n",
    "    print(\"No hay columnas comunes para comparar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
